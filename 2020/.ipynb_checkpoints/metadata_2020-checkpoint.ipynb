{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Data\n",
    "### LMI Capstone Team\n",
    "### Summer Chambers | Steve Morris | Kaleb Shikur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from statistics import mode\n",
    "from sklearn.metrics import ndcg_score, f1_score, average_precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection, ElasticsearchException\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests #gets urls\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 173.79.72.92, port 9200\n",
    "# host = '173.79.72.92'\n",
    "endpoint = 'https://search-lmi-capstone-2-525zkk33t4z5iy6ozqd63ctgmq.us-east-1.es.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'eb7b3348d3c34ce7dc22f263930c51ad', 'cluster_name': '846033058400:lmi-capstone-2', 'cluster_uuid': 'QzTffcNgStmet053IRSP2w', 'version': {'number': '7.9.1', 'build_flavor': 'oss', 'build_type': 'tar', 'build_hash': 'unknown', 'build_date': '2020-11-03T09:54:32.349659Z', 'build_snapshot': False, 'lucene_version': '8.6.2', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "#es = Elasticsearch(endpoint, timeout = 45)\n",
    "es = Elasticsearch(endpoint, timeout=600, max_retries=2, retry_on_timeout=True)\n",
    "\n",
    "\n",
    "\n",
    "print(es.info())\n",
    "\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[{'host': host, 'port': 443}],\n",
    "#     http_auth=auth,\n",
    "#     use_ssl=True,\n",
    "#     verify_certs=True,\n",
    "#     connection_class=RequestsHttpConnection\n",
    "# )\n",
    "# print(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_url = \"https://mikeanders.org/data/CMS/CMS-2020-0088-1604/CMS-2020-0088-1604%20Comment%20MetaData.xlsx\"\n",
    "data = pd.read_excel(metadata_url)\n",
    "data[\"comment_id\"] = [i for i, comment in enumerate(data.Primary)]\n",
    "data = data.replace([\"EUC Policy for 2021\", \"Comment Solicitation: EUC Policy for 2022 and beyond\"], \\\n",
    "             \"Comment Solicitation: EUC Policy for 2021 and beyond\") #combining two sections that can't be split in rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary</th>\n",
       "      <th>Tracking Number</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Supportive?</th>\n",
       "      <th>Comment text</th>\n",
       "      <th>Unique Flag</th>\n",
       "      <th>HeavyHitter</th>\n",
       "      <th>Modified</th>\n",
       "      <th>Form Letter?</th>\n",
       "      <th>FormLetter Y/N</th>\n",
       "      <th>Sheet Name</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMS-2020-0088-9495</td>\n",
       "      <td>1k4-9ivz-162j</td>\n",
       "      <td>MarsdenAdvisors</td>\n",
       "      <td>Applying the APM APP to SSP ACOs</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>We are part of a MIPS APM that consistently sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-14 14:32:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liz Tracker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMS-2020-0088-9494</td>\n",
       "      <td>1k4-9ivz-50bx</td>\n",
       "      <td>MarsdenAdvisors</td>\n",
       "      <td>Applying the APM APP to SSP ACOs</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>We are part of a MIPS APM that consistently sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-14 14:32:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liz Tracker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMS-2020-0088-8582</td>\n",
       "      <td>kev-e48h-ghk4</td>\n",
       "      <td>Kari Kerstetter</td>\n",
       "      <td>Applying the APM APP to SSP ACOs</td>\n",
       "      <td>Opposed</td>\n",
       "      <td>Thank you for the opportunity to provide publi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-09 11:23:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dylan Tracker</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMS-2020-0088-8582</td>\n",
       "      <td>kev-e48h-ghk4</td>\n",
       "      <td>Kari Kerstetter</td>\n",
       "      <td>Revising the SSP Quality Performance Standard</td>\n",
       "      <td>Opposed</td>\n",
       "      <td>...In addition, the move to a 4th decile ACO q...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-09 11:23:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dylan Tracker</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMS-2020-0088-31162</td>\n",
       "      <td>1k4-9jcr-57bp</td>\n",
       "      <td>PBACO Holding, LLC (PBACO)</td>\n",
       "      <td>Applying the APM APP to SSP ACOs</td>\n",
       "      <td>Opposed</td>\n",
       "      <td>We respectfully decline from supporting CMS pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 18:18:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eric Tracker</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Primary Tracking Number                Organization  \\\n",
       "0   CMS-2020-0088-9495   1k4-9ivz-162j             MarsdenAdvisors   \n",
       "1   CMS-2020-0088-9494   1k4-9ivz-50bx             MarsdenAdvisors   \n",
       "2   CMS-2020-0088-8582   kev-e48h-ghk4             Kari Kerstetter   \n",
       "3   CMS-2020-0088-8582   kev-e48h-ghk4             Kari Kerstetter   \n",
       "4  CMS-2020-0088-31162   1k4-9jcr-57bp  PBACO Holding, LLC (PBACO)   \n",
       "\n",
       "                                           Topic Supportive?  \\\n",
       "0               Applying the APM APP to SSP ACOs       Mixed   \n",
       "1               Applying the APM APP to SSP ACOs       Mixed   \n",
       "2               Applying the APM APP to SSP ACOs     Opposed   \n",
       "3  Revising the SSP Quality Performance Standard     Opposed   \n",
       "4               Applying the APM APP to SSP ACOs     Opposed   \n",
       "\n",
       "                                        Comment text  Unique Flag  \\\n",
       "0  We are part of a MIPS APM that consistently sc...            1   \n",
       "1  We are part of a MIPS APM that consistently sc...            1   \n",
       "2  Thank you for the opportunity to provide publi...            1   \n",
       "3  ...In addition, the move to a 4th decile ACO q...            0   \n",
       "4  We respectfully decline from supporting CMS pr...            1   \n",
       "\n",
       "   HeavyHitter            Modified  Form Letter?  FormLetter Y/N  \\\n",
       "0          NaN 2020-09-14 14:32:16           NaN             NaN   \n",
       "1          NaN 2020-09-14 14:32:16           NaN             NaN   \n",
       "2          NaN 2020-10-09 11:23:30           NaN             NaN   \n",
       "3          NaN 2020-10-09 11:23:30           NaN             NaN   \n",
       "4          NaN 2020-10-08 18:18:49           NaN             NaN   \n",
       "\n",
       "      Sheet Name  comment_id  \n",
       "0    Liz Tracker           0  \n",
       "1    Liz Tracker           1  \n",
       "2  Dylan Tracker           2  \n",
       "3  Dylan Tracker           3  \n",
       "4   Eric Tracker           4  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Applying the APM APP to SSP ACOs                                                             245\n",
       "Revising the SSP Quality Performance Standard                                                 71\n",
       "Updating Primary Care Services Definition for Assignment                                      48\n",
       "Comment Solicitation: EUC Policy for 2020                                                     41\n",
       "Proposed Changes to CAHPS for 2020                                                            33\n",
       "Comment Solicitation: EUC Policy for 2021 and beyond                                          29\n",
       "Other: Unsolicited                                                                            25\n",
       "Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses     16\n",
       "Revising Policy for Determining the Amount of Repayment Mechanism                             15\n",
       "Applicability of Policies to Track 1+ Model ACOs                                               4\n",
       "Quality Redesign: Compliance with the Quality Performance Standard                             3\n",
       "Updating the Process Used to validate ACO Quality Data Reporting                               2\n",
       "Quality Redesign: Proposed Technical Changes to Quality Regulation Text                        1\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Topic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_url = \"https://mikeanders.org/data/CMS/CMS-2020-0088-1604/Rule/CMS-2020-0088-1604.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdict = {\"Applying the APM APP to SSP ACOs\": [\"b. Applying the Alternative Payment Model (APM) Performance Pathway (APP) to Shared Savings Program ACOs\", \\\n",
    "                                                  \"c. Shared Savings Program Quality Performance Standard\"], \\\n",
    "           \"Revising the SSP Quality Performance Standard\": [\"c. Shared Savings Program Quality Performance Standard\", \\\n",
    "                                                             \"d. Use of ACO Quality Performance in Determining Shared Savings and Shared Losses\"], \\\n",
    "           \"Comment Solicitation: EUC Policy for 2020\": [\"2. Comment Solicitation on Modifications to the Extreme and Uncontrollable Circumstances Policy for Performance Year 2020\", \\\n",
    "                                                         \"J. Proposal To Remove Selected National Coverage Determinations\"], \\\n",
    "           \"Updating Primary Care Services Definition for Assignment\": [\"2. Revisions to the Definition of Primary Care Services used in Shared Savings Program Beneficiary Assignment\", \\\n",
    "                                                                        \"3. Reducing the Amount of Repayment Mechanisms for Eligible ACOs\"], \\\n",
    "           \"Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses\": [\"d. Use of ACO Quality Performance in Determining Shared Savings and Shared Losses\", \\\n",
    "                                                                                                         \"e. Compliance With the Quality Performance Standard\"], \\\n",
    "           \"Quality Redesign: Compliance with the Quality Performance Standard\": [\"e. Compliance With the Quality Performance Standard\", \\\n",
    "                                                                                  \"f. Updating the Process Used To Validate ACO Quality Data Reporting\"], \\\n",
    "           \"Proposed Changes to CAHPS for 2020\": [\"1. Proposed Changes to the CAHPS for ACOs Reporting Requirements for Performance Year 2020\", \\\n",
    "                                                  \"2. Comment Solicitation on Modifications to the Extreme and Uncontrollable Circumstances Policy for Performance Year 2020\"], \\\n",
    "           \"Applicability of Policies to Track 1+ Model ACOs\": [\"4. Applicability of Policies to Track 1+ Model ACOs\", \\\n",
    "                                                                \"I. Modifications to Quality Reporting Requirements and Comment Solicitation on Modifications to the Extreme and Uncontrollable Circumstances Policy for Performance Year 2020\"], \\\n",
    "           \"Revising Policy for Determining the Amount of Repayment Mechanism\": [\"3. Reducing the Amount of Repayment Mechanisms for Eligible ACOs\", \\\n",
    "                                                                                 \"4. Applicability of Policies to Track 1+ Model ACOs\"], \\\n",
    "           \"Quality Redesign: Proposed Technical Changes to Quality Regulation Text\":  [\"h. Proposed Technical Changes To Incorporate References to Revised Quality Performance Standard\", \\\n",
    "                                                                                        \"2. Revisions to the Definition of Primary Care Services Used in Shared Savings Program Beneficiary Assignment\"], \\\n",
    "           \"Comment Solicitation: EUC Policy for 2021 and beyond\": [\"g. Changes to the Extreme and Uncontrollable Circumstances Policy for Performance Year 2021\", \\\n",
    "                                                                    \"h. Proposed Technical Changes To Incorporate References to Revised Quality Performance Standard\"], \\\n",
    "           \"Updating the Process Used to validate ACO Quality Data Reporting\": [\"f. Updating the Process Used To Validate ACO Quality Data Reporting\", \\\n",
    "                                                                                \"g. Changes to the Extreme and Uncontrollable Circumstances Policy for Performance Year 2021\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_headers(rule_url, startdict):\n",
    "\n",
    "    alltxt = requests.get(rule_url).text.lower()#.encode('unicode_escape').decode() #encodes like raw strings\n",
    "    for key in startdict.keys():\n",
    "        startdict[key] = [val.lower() for val in startdict[key]]\n",
    "    \n",
    "    rulechunks = []\n",
    "    \n",
    "    for key, value in startdict.items():    \n",
    "       splitlist = alltxt.split(value[0]) #split on start of desired section\n",
    "       split_further = splitlist[1].split(value[1]) #split again on start of undesired section\n",
    "       rulechunks.append({\"section\": key, \"text\": (value[0]+split_further[0])}) #choose only first half to upload to dict\n",
    "\n",
    "    return rulechunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Applying the APM APP to SSP ACOs': 23299,\n",
       " 'Revising the SSP Quality Performance Standard': 7592,\n",
       " 'Comment Solicitation: EUC Policy for 2020': 10933,\n",
       " 'Updating Primary Care Services Definition for Assignment': 45692,\n",
       " 'Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses': 9614,\n",
       " 'Quality Redesign: Compliance with the Quality Performance Standard': 18527,\n",
       " 'Proposed Changes to CAHPS for 2020': 8890,\n",
       " 'Applicability of Policies to Track 1+ Model ACOs': 9995,\n",
       " 'Revising Policy for Determining the Amount of Repayment Mechanism': 22281,\n",
       " 'Quality Redesign: Proposed Technical Changes to Quality Regulation Text': 3041,\n",
       " 'Comment Solicitation: EUC Policy for 2021 and beyond': 11322,\n",
       " 'Updating the Process Used to validate ACO Quality Data Reporting': 2638}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split1 = splitRule_headers(rule_url, startdict)\n",
    "headers_id_list = [doc[\"section\"] for doc in split1]\n",
    "lengths = {chunk[\"section\"]: len(chunk[\"text\"]) for chunk in split1}\n",
    "print(\"sections:\", len(lengths))\n",
    "lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_line_hybrid(rule_url):\n",
    "    new_rule_chunks = []\n",
    "    chunks = splitRule_headers(rule_url, startdict)\n",
    "    for doc in chunks:\n",
    "        paragraphs = doc[\"text\"].split('\\r\\n')\n",
    "        #add new lines while under 6000 characters\n",
    "        for i in range(len(paragraphs) - 1):\n",
    "            while i < (len(paragraphs)-1) and len(paragraphs[i]) < 6000:\n",
    "                paragraphs[i] += paragraphs[i+1]\n",
    "                del(paragraphs[i+1])\n",
    "        for i in range(len(paragraphs)):\n",
    "            new_rule_chunks.append({\"section\": doc[\"section\"]+\"_\"+str(i), \"text\": paragraphs[i]})\n",
    "    return new_rule_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Applying the APM APP to SSP ACOs_0': 6267,\n",
       " 'Applying the APM APP to SSP ACOs_1': 8189,\n",
       " 'Applying the APM APP to SSP ACOs_2': 6735,\n",
       " 'Applying the APM APP to SSP ACOs_3': 2046,\n",
       " 'Revising the SSP Quality Performance Standard_0': 6873,\n",
       " 'Revising the SSP Quality Performance Standard_1': 703,\n",
       " 'Comment Solicitation: EUC Policy for 2020_0': 6352,\n",
       " 'Comment Solicitation: EUC Policy for 2020_1': 4557,\n",
       " 'Updating Primary Care Services Definition for Assignment_0': 6489,\n",
       " 'Updating Primary Care Services Definition for Assignment_1': 6307,\n",
       " 'Updating Primary Care Services Definition for Assignment_2': 6107,\n",
       " 'Updating Primary Care Services Definition for Assignment_3': 8129,\n",
       " 'Updating Primary Care Services Definition for Assignment_4': 7356,\n",
       " 'Updating Primary Care Services Definition for Assignment_5': 6711,\n",
       " 'Updating Primary Care Services Definition for Assignment_6': 4391,\n",
       " 'Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses_0': 6169,\n",
       " 'Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses_1': 3403,\n",
       " 'Quality Redesign: Compliance with the Quality Performance Standard_0': 6853,\n",
       " 'Quality Redesign: Compliance with the Quality Performance Standard_1': 6576,\n",
       " 'Quality Redesign: Compliance with the Quality Performance Standard_2': 5052,\n",
       " 'Proposed Changes to CAHPS for 2020_0': 6362,\n",
       " 'Proposed Changes to CAHPS for 2020_1': 2508,\n",
       " 'Applicability of Policies to Track 1+ Model ACOs_0': 6121,\n",
       " 'Applicability of Policies to Track 1+ Model ACOs_1': 3840,\n",
       " 'Revising Policy for Determining the Amount of Repayment Mechanism_0': 7405,\n",
       " 'Revising Policy for Determining the Amount of Repayment Mechanism_1': 7046,\n",
       " 'Revising Policy for Determining the Amount of Repayment Mechanism_2': 6673,\n",
       " 'Revising Policy for Determining the Amount of Repayment Mechanism_3': 1103,\n",
       " 'Quality Redesign: Proposed Technical Changes to Quality Regulation Text_0': 3023,\n",
       " 'Comment Solicitation: EUC Policy for 2021 and beyond_0': 6323,\n",
       " 'Comment Solicitation: EUC Policy for 2021 and beyond_1': 4981,\n",
       " 'Updating the Process Used to validate ACO Quality Data Reporting_0': 2630}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2 = splitRule_line_hybrid(rule_url)\n",
    "hybrid_id_list = [doc[\"section\"] for doc in split2]\n",
    "lengths = {chunk[\"section\"]: len(chunk[\"text\"]) for chunk in split2}\n",
    "print(\"sections:\", len(lengths))\n",
    "lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Splits to ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "##es.indices.delete(index='2020hybrid_1shard', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesplit_toES(rulechunks, es_index):\n",
    "    for chunk in rulechunks:\n",
    "            res = es.index(index=es_index, id=chunk[\"section\"], body=chunk, doc_type='_doc')\n",
    "            es.indices.refresh(index=es_index)\n",
    "    print(\"Last id uploaded:\", chunk[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: Updating the Process Used to validate ACO Quality Data Reporting\n"
     ]
    }
   ],
   "source": [
    "rulesplit_1shard = splitRule_headers(rule_url, startdict)\n",
    "upload_1shard = rulesplit_toES(rulesplit_1shard, \"2020headers_1shard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: Updating the Process Used to validate ACO Quality Data Reporting_0\n"
     ]
    }
   ],
   "source": [
    "rulesplit_1shard = splitRule_line_hybrid(rule_url)\n",
    "upload_1shard = rulesplit_toES(rulesplit_1shard, \"2020hybrid_1shard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "termVectorBody = {\n",
    "  \"fields\" : [\"text\"],\n",
    "  \"term_statistics\" : True,\n",
    "  \"field_statistics\" : True,\n",
    "  \"offsets\" : False,\n",
    "  \"payloads\" : False,\n",
    "  \"positions\" : False,\n",
    "    \"filter\": {\n",
    "    \"max_num_terms\": 30,\n",
    "    \"min_term_freq\": 1,\n",
    "    \"min_doc_freq\": 11 ## 90% of documents\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "termvecs = dict()\n",
    "for section in headers_id_list:\n",
    "    result = es.termvectors(index = \"2020headers_1shard\", id = section, body= termVectorBody)\n",
    "    termvecs[section] = list(result['term_vectors']['text']['terms'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ar',\n",
       " 'current',\n",
       " 'determin',\n",
       " 'chang',\n",
       " 'continu',\n",
       " 'address',\n",
       " 'therefor',\n",
       " 'data',\n",
       " 'applic',\n",
       " 'elig',\n",
       " 'period',\n",
       " 'believ',\n",
       " '2021',\n",
       " 'begin']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = [value for key, value in termvecs.items()]\n",
    "common_words = list(set([word for list1 in common_words for word in list1]))\n",
    "common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "termVectorBody = {\n",
    "  \"fields\" : [\"text\"],\n",
    "  \"term_statistics\" : True,\n",
    "  \"field_statistics\" : True,\n",
    "  \"offsets\" : False,\n",
    "  \"payloads\" : False,\n",
    "  \"positions\" : False,\n",
    "    \"filter\": {\n",
    "    \"max_num_terms\": 10,\n",
    "    \"min_term_freq\": 1,\n",
    "    \"min_doc_freq\": 1,\n",
    "    \"max_doc_freq\": 10\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "termvecs = dict()\n",
    "for section in headers_id_list:\n",
    "    result = es.termvectors(index = \"2020headers_1shard\", id = section, body= termVectorBody)\n",
    "    termvecs[section] = list(result['term_vectors']['text']['terms'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying the APM APP to SSP ACOs \n",
      " ['align', 'apm', 'app', 'categori', 'measur', 'mip', 'qualiti', 'report', 'score', 'set'] \n",
      "\n",
      "\n",
      "Revising the SSP Quality Performance Standard \n",
      " ['40th', 'categori', 'exclud', 'mip', 'percentil', 'qp', 'qualiti', 'score', 'specifi', 'standard'] \n",
      "\n",
      "\n",
      "Comment Solicitation: EUC Policy for 2020 \n",
      " ['2020', 'complet', 'extrem', 'impact', 'measur', 'phe', 'qualiti', 'report', 'score', 'uncontrol'] \n",
      "\n",
      "\n",
      "Updating Primary Care Services Definition for Assignment \n",
      " ['assign', 'care', 'code', 'cpt', 'hcpc', 'manag', 'primari', 'profession', 'servic', 'snf'] \n",
      "\n",
      "\n",
      "Quality Redesign: Use of ACO Quality Performance in Determining Shared Savings and Losses \n",
      " ['d', 'enhanc', 'level', 'loss', 'model', 'percent', 'qualiti', 'rate', 'side', 'track'] \n",
      "\n",
      "\n",
      "Quality Redesign: Compliance with the Quality Performance Standard \n",
      " ['425.316', 'agreement', 'consecut', 'enter', 'fail', 'meet', 'qualiti', 'renew', 'standard', 'termin'] \n",
      "\n",
      "\n",
      "Proposed Changes to CAHPS for 2020 \n",
      " ['2020', 'administr', 'cahp', 'care', 'impact', 'pandem', 'primari', 'sampl', 'survei', 'visit'] \n",
      "\n",
      "\n",
      "Applicability of Policies to Track 1+ Model ACOs \n",
      " ['agreement', 'home', 'infus', 'model', 'notif', 'option', 'servic', 'therapi', 'thi', 'track'] \n",
      "\n",
      "\n",
      "Revising Policy for Determining the Amount of Repayment Mechanism \n",
      " ['425.204', 'agreement', 'amount', 'arrang', 'exist', 'f', 'mechan', 'renew', 'repay', 'support'] \n",
      "\n",
      "\n",
      "Quality Redesign: Proposed Technical Changes to Quality Regulation Text \n",
      " ['425.510', '425.512', 'add', 'descript', 'qualiti', 'refer', 'revis', 'specifi', 'standard', 'subpart'] \n",
      "\n",
      "\n",
      "Comment Solicitation: EUC Policy for 2021 and beyond \n",
      " ['affect', 'categori', 'circumst', 'extrem', 'impact', 'mip', 'qualiti', 'report', 'score', 'uncontrol'] \n",
      "\n",
      "\n",
      "Updating the Process Used to validate ACO Quality Data Reporting \n",
      " ['audit', 'match', 'medic', 'mip', 'overal', 'process', 'qualiti', 'record', 'report', 'valid'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in termvecs.items():\n",
    "    print(key, \"\\n\", value, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXCEL COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel2020 = {num:text for num, text in zip(data[\"comment_id\"], data[\"Comment text\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(excel2020)\n",
    "f = open('excel2020.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate excel comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_excel2020 = list(excel2020.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeDuper import *\n",
    "duplicates = getDupes(list_excel2020)\n",
    "print(len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupdict = {}\n",
    "for i, dup in enumerate(duplicates):\n",
    "    dupdict[i] = [list_excel2020[idx][0:120] for idx in dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dupdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Truth Dictionary of Unique Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_topics = {}\n",
    "for dup_list in duplicates: #iterate through the duplicate lists\n",
    "    topic_list = []\n",
    "    for dup in dup_list: #iterate through the comments\n",
    "        topic_list.append(data.loc[data[\"comment_id\"] == dup, 'Topic'].item()) #find topic for that comment\n",
    "    dup_topics[int(dup)] = list(set(topic_list)) #choose last comment in list, map it to only unique topics in that duplicates list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_dict = dict(sorted(dup_topics.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write truth_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(truth_dict)\n",
    "f = open('2020truth_dict.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read truth_dict (avoid running duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2020truth_dict.json') as f:\n",
    "    truth_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only unique comments text, make lowercase, replace \\t etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_excel2020 = {key:value.lower().replace('\\t', \" \").replace('\\n', \" \").replace('\\r', \" \").replace('\\s', \" \")\\\n",
    "                    for key, value in excel2020.items() if key in list(truth_dict.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write unique comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(unique_excel2020)\n",
    "f = open('unique_excel2020.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read unique comments (avoid running duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_excel2020.json') as f:\n",
    "    unique_excel2020 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unique DataFrame with topics as columns, ones and zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(data.Topic.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1c892b05dc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtopic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "topic_df = data.copy()\n",
    "for topic in topics:\n",
    "    topic_df[topic] = np.empty_like(data.Topic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8c481953fbe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_df' is not defined"
     ]
    }
   ],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRAPE COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_url = \"https://mikeanders.org/data/CMS/CMS-2020-0088-1604/Comments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27263 14757 4081. 12407 9318. 7951_ 6346. 22950 25087 10310 19016 11720 5169. 11847 26170 16844 19308 5615_ 16732 29378 10132 21984 9460. 31050 27775 24212 5148. 23098 5446. 30719 20607 18248 3580. 6017. 17690 3873. 16401 11983 7781. 29013 30443 25489 13666 7303. 28679 26773 14237 26913 27652 2383. 29581 4959. 7359. 6914. 14712 7314. 6766. 17430 2725. 30465 22797 22507 2862. 11882 19051 1740. 26872 21773 13936 7426_ 12483 17048 8911. 24176 3100. 25565 21589 4851. 28195 4280. 2722. 25510 20831 22954 3805. 22975 27428 7039. 21402 28609 12890 26777 4139. 25190 23669 16279 20372 23417 18884 15849 26058 7196. 31315 15342 17861 20653 12522 23079 6932. 20846 24710 31121 16031 18438 2271. 29538 28145 2571. 12597 8130. 5170. 21016 21611 19436 10114 23130 28470 28359 7163. 24545 8714. 24722 12659 6621. 25738 29803 25459 23234 12218 21052 23291 7433. 25182 25817 12374 15718 23309 16215 8790. 5153. 9578_ 22221 8782. 22024 26763 11121 29343 14207 15870 3601. 4388. 13142 10516 13236 29831 16123 4046. 10727 13590 2479. 24553 24396 27553 31287 23208 2165. 8569. 8965. 19088 26296 19579 19450 18505 20209 20590 13500 18743 31329 2581. 16710 23034 22324 14732 26644 8533. 12087 22599 13417 18121 11302 25171 30037 28796 14666 27134 6777. 2272. 23350 14325 9724. 13054 13602 23779 17959 23898 22158 15700 29255 30264 27647 5157_ 23023 25716 11821 3132. 12554 2880. 22684 12123 28826 30517 14318 19117 28884 5143. 7382. 4710. 28663 8037. 3852. 8908. 22789 17747 14911 26546 21304 16892 8637. 4496. 18013 3870. 10973 9976. 26951 25441 9237. 22155 20130 17636 18731 21744 4780. 8162. 18711 5645. 9331. 23153 5131_ 30621 3434. 10499 30057 13070 8230. 29395 10753 14093 9455. 10597 15389 13637 6145. 12440 14475 8879. 11207 10442 19914 23543 29671 8493. 8069. 21127 28908 27410 2940. 12539 1857. 8819. 15743 3631. 22848 21709 20795 5239. 22430 29477 19243 4187. 25559 25662 19777 24632 29880 6106. 19203 29019 25306 11611 24689 20173 29730 2270. 6198. 23630 24701 4445. 26225 29470 4185. 31093 25263 18071 27251 6362. 22677 30689 25378 7130. 7820. 16236 26570 3543. 19931 22590 11578 11931 19621 9610. 8167. 12451 9921. 11911 25583 8177. 30704 19813 29436 5486. 4404. 22310 9517. 2943. 13165 15099 5779. 14069 27886 9418. 18253 18631 28213 28987 23851 2787. 11053 4911. 12769 4955. 7710. 5557. 19955 19139 11459 25232 14129 28762 14379 15726 13401 20307 7984_ 19861 15997 26693 7969. 15319 26843 3182. 22829 "
     ]
    }
   ],
   "source": [
    "response = requests.get(comment_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "a_tags = soup.findAll(\"a\")\n",
    "links = [tag[\"href\"] for tag in a_tags]\n",
    "txt_links = [link for link in links if '.txt' in link]\n",
    "comments = {}\n",
    "txt_sampled = sample(txt_links, 400)\n",
    "for suffix in txt_sampled:\n",
    "    comments[suffix[14:19]] = requests.get(comment_url+suffix).text.lower()\n",
    "    print(suffix[14:19], end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_json = json.dumps(comments)\n",
    "f = open('comments2020.json','w')\n",
    "f.write(comment_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid scraping comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments2020.json') as f:\n",
    "    comments2020 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate comments, comments less than 30 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'26913': '\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n',\n",
       " '22797': 'please see attached letter',\n",
       " '8911.': 'see attached file(s)',\n",
       " '24176': 'see attached file(s)',\n",
       " '28195': 'see attached file(s)',\n",
       " '22954': 'see attached file(s)',\n",
       " '22975': 'please see attached file.',\n",
       " '31315': 'see attached',\n",
       " '2571.': 'see attached file(s)',\n",
       " '13590': 'see attached file(s)',\n",
       " '24553': 'see attached file(s)',\n",
       " '19450': 'see attached file(s)',\n",
       " '20209': 'see attached file(s)',\n",
       " '13417': 'please see attached file.',\n",
       " '14666': 'see attached file(s)',\n",
       " '30264': 'my letter is attached.',\n",
       " '10753': 'see attached file(s)',\n",
       " '14093': 'see attached',\n",
       " '14129': 'see attached file(s)'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_comments2020 = {key: val for key, val in comments2020.items() if len(val) >= 30}\n",
    "short_ones = {key: val for key, val in comments2020.items() if len(val) < 30}\n",
    "list_reduced_comments2020 = list(reduced_comments2020.values())\n",
    "len(reduced_comments2020)\n",
    "short_ones #these seem okay to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from DeDuper import *\n",
    "duplicates = getDupes(list_reduced_comments2020)\n",
    "print(len(duplicates))\n",
    "#duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupdict = {}\n",
    "for i, dup in enumerate(duplicates):\n",
    "    dupdict[i] = [list_reduced_comments2020[idx][0:120] for idx in dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dupdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_deleted = []\n",
    "for num, duplist in enumerate(duplicates):\n",
    "    for idx, comment in enumerate(list_reduced_comments2020):\n",
    "        if idx in duplist[:-1]:\n",
    "            tb_deleted.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tb_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_comments2020 = {key:value for key, value in reduced_comments2020.items() if value not in tb_deleted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_comments2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(unique_comments2020)\n",
    "f = open('unique_comments2020.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid running duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_comments2020.json') as f:\n",
    "    unique_comments2020 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up longer comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_comments = {key:value for key, value in unique_comments2020.items() if len(value) > 5000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded2020 = unique_comments2020.copy()\n",
    "for key, value in long_comments.items():\n",
    "    paragraphs = value.split('\\n')\n",
    "    for i in range(len(paragraphs) - 1):\n",
    "        while i < (len(paragraphs) - 1) and len(paragraphs[i]) < 4800:\n",
    "            paragraphs[i] += paragraphs[i+1]\n",
    "            del(paragraphs[i+1])\n",
    "    for i in range(len(paragraphs)):\n",
    "        expanded2020[key+'_'+str(i)] = paragraphs[i]\n",
    "expanded2020 = {key:value for key, value in expanded2020.items() if key not in list(long_comments.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{key:len(value) for key, value in expanded2020.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove \\r, \\n, \\s, and any weird or non-ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded2020 = {key:value.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\s\", \" \") for key, value in expanded2020.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in expanded2020.items():\n",
    "    expanded2020[key] = ''.join(c for c in value if c in string.printable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(expanded2020)\n",
    "f = open('expanded2020.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid expanding/cleaning comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('expanded2020.json') as f:\n",
    "    expanded2020 = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
