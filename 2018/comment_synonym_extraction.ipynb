{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'eb7b3348d3c34ce7dc22f263930c51ad', 'cluster_name': '846033058400:lmi-capstone-2', 'cluster_uuid': 'QzTffcNgStmet053IRSP2w', 'version': {'number': '7.9.1', 'build_flavor': 'oss', 'build_type': 'tar', 'build_hash': 'unknown', 'build_date': '2020-11-03T09:54:32.349659Z', 'build_snapshot': False, 'lucene_version': '8.6.2', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "host = 'https://search-lmi-capstone-2-525zkk33t4z5iy6ozqd63ctgmq.us-east-1.es.amazonaws.com'\n",
    "es = Elasticsearch(host)\n",
    "print(es.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaleb\\\\Documents\\\\GitHub\\\\kaleb_LMI_local\\\\LMI-Capstone-1\\\\2018'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open('CMS-2018-0101-0001.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ('feel' in content):\n",
    "#     print(\"word foud\")\n",
    "# else:\n",
    "#     print(\"word not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_comments = pd.read_json('unique_comments2018.json')\n",
    "fjson = open('unique_comments2018.json')\n",
    "unique_comments = json.load(fjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = unique_comments.keys()\n",
    "values = unique_comments.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_upload(comments_dict, es_index):\n",
    "    for key, vals in comments_dict.items():\n",
    "            values_dict = {'text':vals}\n",
    "            res = es.index(index=es_index, id=key, body=values_dict, doc_type='_doc')\n",
    "            es.indices.refresh(index=es_index)\n",
    "    print(\"Last id uploaded:\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: 0467\n"
     ]
    }
   ],
   "source": [
    "comment_upload(unique_comments,'comment_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "termVectorBody = {\n",
    "  \"fields\" : [\"text\"],\n",
    "  \"term_statistics\" : True,\n",
    "  \"field_statistics\" : True,\n",
    "  \"offsets\" : False,\n",
    "  \"payloads\" : False,\n",
    "  \"positions\" : False,\n",
    "    \"filter\": {\n",
    "    \"max_num_terms\": 20,\n",
    "    \"min_term_freq\": 1,\n",
    "    \"min_doc_freq\": 1,\n",
    "    \"max_doc_freq\": 5\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "termvecs = dict()\n",
    "for section in keys:\n",
    "    result = es.termvectors(index = \"comment_index\", id = section, body= termVectorBody)\n",
    "    if (result['found']):\n",
    "        termvecs[section] = list(result['term_vectors']['text']['terms'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-3d8ea2919584>:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  words = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in termvecs.items() ]))\n"
     ]
    }
   ],
   "source": [
    "# words = pd.DataFrame(data=termvecs).T\n",
    "words = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in termvecs.items() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004</th>\n",
       "      <th>0005</th>\n",
       "      <th>0006</th>\n",
       "      <th>0007</th>\n",
       "      <th>0008</th>\n",
       "      <th>0009</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>...</th>\n",
       "      <th>0399</th>\n",
       "      <th>0401</th>\n",
       "      <th>0404</th>\n",
       "      <th>0408</th>\n",
       "      <th>0419</th>\n",
       "      <th>0423</th>\n",
       "      <th>0428</th>\n",
       "      <th>0437</th>\n",
       "      <th>0438</th>\n",
       "      <th>0467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accord</td>\n",
       "      <td>absolut</td>\n",
       "      <td>aco'</td>\n",
       "      <td>allianc</td>\n",
       "      <td>clarif</td>\n",
       "      <td>100</td>\n",
       "      <td>0938</td>\n",
       "      <td>compani</td>\n",
       "      <td>cannot</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1034</td>\n",
       "      <td>ceic4</td>\n",
       "      <td>amount</td>\n",
       "      <td>crisi</td>\n",
       "      <td>80</td>\n",
       "      <td>16th</td>\n",
       "      <td>210</td>\n",
       "      <td>baptist</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alik</td>\n",
       "      <td>aco'</td>\n",
       "      <td>advis</td>\n",
       "      <td>attain</td>\n",
       "      <td>my</td>\n",
       "      <td>aledad</td>\n",
       "      <td>1,100</td>\n",
       "      <td>complex</td>\n",
       "      <td>reserv</td>\n",
       "      <td>alter</td>\n",
       "      <td>...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2333</td>\n",
       "      <td>cific</td>\n",
       "      <td>bill</td>\n",
       "      <td>cross</td>\n",
       "      <td>aco√¢</td>\n",
       "      <td>1993</td>\n",
       "      <td>67756</td>\n",
       "      <td>disagre</td>\n",
       "      <td>0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>broom</td>\n",
       "      <td>antagon</td>\n",
       "      <td>becom</td>\n",
       "      <td>bend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>allevi</td>\n",
       "      <td>414</td>\n",
       "      <td>cultur</td>\n",
       "      <td>worth</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>2019</td>\n",
       "      <td>82.8</td>\n",
       "      <td>communitv</td>\n",
       "      <td>coast</td>\n",
       "      <td>cut</td>\n",
       "      <td>deliv</td>\n",
       "      <td>3832</td>\n",
       "      <td>attn</td>\n",
       "      <td>foot</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catalyst.nejm.org</td>\n",
       "      <td>bend</td>\n",
       "      <td>feel</td>\n",
       "      <td>blame</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cardiologist</td>\n",
       "      <td>42</td>\n",
       "      <td>doubt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cash</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>98557</td>\n",
       "      <td>defin</td>\n",
       "      <td>diabet</td>\n",
       "      <td>diseas</td>\n",
       "      <td>disast</td>\n",
       "      <td>384</td>\n",
       "      <td>biggest</td>\n",
       "      <td>give</td>\n",
       "      <td>206.216.2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constantli</td>\n",
       "      <td>bring</td>\n",
       "      <td>impract</td>\n",
       "      <td>curv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>certif</td>\n",
       "      <td>425</td>\n",
       "      <td>enforc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduat</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>cah</td>\n",
       "      <td>f</td>\n",
       "      <td>equip</td>\n",
       "      <td>disord</td>\n",
       "      <td>field</td>\n",
       "      <td>41863</td>\n",
       "      <td>cheyenn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diminish</td>\n",
       "      <td>burnout</td>\n",
       "      <td>qp</td>\n",
       "      <td>cut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contain</td>\n",
       "      <td>administ</td>\n",
       "      <td>game</td>\n",
       "      <td>NaN</td>\n",
       "      <td>isn't</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>care.√¢</td>\n",
       "      <td>fohc</td>\n",
       "      <td>exam</td>\n",
       "      <td>futur</td>\n",
       "      <td>learn</td>\n",
       "      <td>alfero</td>\n",
       "      <td>counti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dynam</td>\n",
       "      <td>chanc</td>\n",
       "      <td>regular</td>\n",
       "      <td>death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>count</td>\n",
       "      <td>aggress</td>\n",
       "      <td>highli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kind</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>clallam</td>\n",
       "      <td>ny</td>\n",
       "      <td>ey</td>\n",
       "      <td>mix</td>\n",
       "      <td>natur</td>\n",
       "      <td>andrew</td>\n",
       "      <td>elast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>along</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entic</td>\n",
       "      <td>concept</td>\n",
       "      <td>septemb</td>\n",
       "      <td>effectu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>destroi</td>\n",
       "      <td>at45</td>\n",
       "      <td>larger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>margin</td>\n",
       "      <td>...</td>\n",
       "      <td>adequ</td>\n",
       "      <td>counti</td>\n",
       "      <td>tk</td>\n",
       "      <td>florida</td>\n",
       "      <td>opioid</td>\n",
       "      <td>next</td>\n",
       "      <td>cah</td>\n",
       "      <td>embrac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>association√¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>forc</td>\n",
       "      <td>drg</td>\n",
       "      <td>taken</td>\n",
       "      <td>fear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fqhc</td>\n",
       "      <td>behind</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reserv</td>\n",
       "      <td>...</td>\n",
       "      <td>administ</td>\n",
       "      <td>district</td>\n",
       "      <td>www.chcanys.org</td>\n",
       "      <td>foot</td>\n",
       "      <td>particularli</td>\n",
       "      <td>now</td>\n",
       "      <td>chair</td>\n",
       "      <td>franci</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assumpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hold</td>\n",
       "      <td>duti</td>\n",
       "      <td>timelin</td>\n",
       "      <td>government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "      <td>cfr</td>\n",
       "      <td>misguid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>starter</td>\n",
       "      <td>...</td>\n",
       "      <td>collabor</td>\n",
       "      <td>harbor</td>\n",
       "      <td>york</td>\n",
       "      <td>invok</td>\n",
       "      <td>substanc</td>\n",
       "      <td>opioid</td>\n",
       "      <td>charli</td>\n",
       "      <td>frontier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>barton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inevit</td>\n",
       "      <td>enforc</td>\n",
       "      <td>undu</td>\n",
       "      <td>hackensack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knew</td>\n",
       "      <td>costli</td>\n",
       "      <td>partnership</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>concern</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl</td>\n",
       "      <td>coburn</td>\n",
       "      <td>kansa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>landscap</td>\n",
       "      <td>face</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interestingli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>midlevel</td>\n",
       "      <td>fatal</td>\n",
       "      <td>primarili</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>embrac</td>\n",
       "      <td>kittita</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plai</td>\n",
       "      <td>jennif</td>\n",
       "      <td>kelli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mostashari</td>\n",
       "      <td>hand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>leakag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>np</td>\n",
       "      <td>fear</td>\n",
       "      <td>reinvent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>expenditur</td>\n",
       "      <td>klickitat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qualifi</td>\n",
       "      <td>keith</td>\n",
       "      <td>mechan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enrolle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>outlin</td>\n",
       "      <td>lift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lessen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>orthopedist</td>\n",
       "      <td>greatest</td>\n",
       "      <td>surviv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>held</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>render</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retain</td>\n",
       "      <td>lundblad</td>\n",
       "      <td>mr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fiscal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>quit</td>\n",
       "      <td>penalti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>menack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pa</td>\n",
       "      <td>highli</td>\n",
       "      <td>typic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ii.a</td>\n",
       "      <td>margin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>successfulli</td>\n",
       "      <td>mackinnei</td>\n",
       "      <td>order</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fragil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reform</td>\n",
       "      <td>statist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pcmh</td>\n",
       "      <td>induc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>month</td>\n",
       "      <td>mason</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suffici</td>\n",
       "      <td>mcbride</td>\n",
       "      <td>pottorff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>retriev</td>\n",
       "      <td>strategi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perhap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pcp</td>\n",
       "      <td>live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>onli</td>\n",
       "      <td>pacif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transform</td>\n",
       "      <td>mueller</td>\n",
       "      <td>situat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>technic</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>predetermin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>practition</td>\n",
       "      <td>market</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>them</td>\n",
       "      <td>phd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>triniti</td>\n",
       "      <td>object</td>\n",
       "      <td>st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>understood</td>\n",
       "      <td>variat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>someon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sens</td>\n",
       "      <td>product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>total</td>\n",
       "      <td>prosser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trust</td>\n",
       "      <td>ph.d</td>\n",
       "      <td>street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jacquelin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>virtual</td>\n",
       "      <td>volum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>subacut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ud</td>\n",
       "      <td>threaten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>window</td>\n",
       "      <td>vallei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>√Ø</td>\n",
       "      <td>timothi</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jacquelineb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows √ó 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0002      0003     0004           0005    0006          0007  \\\n",
       "0              accord   absolut     aco'        allianc  clarif           100   \n",
       "1                alik      aco'    advis         attain      my        aledad   \n",
       "2               broom   antagon    becom           bend     NaN        allevi   \n",
       "3   catalyst.nejm.org      bend     feel          blame     NaN  cardiologist   \n",
       "4          constantli     bring  impract           curv     NaN        certif   \n",
       "5            diminish   burnout       qp            cut     NaN       contain   \n",
       "6               dynam     chanc  regular          death     NaN         count   \n",
       "7               entic   concept  septemb        effectu     NaN       destroi   \n",
       "8                forc       drg    taken           fear     NaN          fqhc   \n",
       "9                hold      duti  timelin     government     NaN          home   \n",
       "10             inevit    enforc     undu     hackensack     NaN          knew   \n",
       "11           landscap      face      NaN  interestingli     NaN      midlevel   \n",
       "12         mostashari      hand      NaN         leakag     NaN            np   \n",
       "13             outlin      lift      NaN         lessen     NaN   orthopedist   \n",
       "14               quit   penalti      NaN         menack     NaN            pa   \n",
       "15             reform   statist      NaN          onset     NaN          pcmh   \n",
       "16            retriev  strategi      NaN         perhap     NaN           pcp   \n",
       "17            technic    target      NaN    predetermin     NaN    practition   \n",
       "18         understood    variat      NaN         someon     NaN          sens   \n",
       "19            virtual     volum      NaN        subacut     NaN            ud   \n",
       "\n",
       "        0008         0009    0010     0011  ...        0399       0401  \\\n",
       "0       0938      compani  cannot      100  ...          10       1034   \n",
       "1      1,100      complex  reserv    alter  ...        2017       2333   \n",
       "2        414       cultur   worth       am  ...        2019       82.8   \n",
       "3         42        doubt     NaN     cash  ...          30      98557   \n",
       "4        425       enforc     NaN  graduat  ...          31        cah   \n",
       "5   administ         game     NaN    isn't  ...           7     care.√¢   \n",
       "6    aggress       highli     NaN     kind  ...           9    clallam   \n",
       "7       at45       larger     NaN   margin  ...       adequ     counti   \n",
       "8     behind         left     NaN   reserv  ...    administ   district   \n",
       "9        cfr      misguid     NaN  starter  ...    collabor     harbor   \n",
       "10    costli  partnership     NaN      NaN  ...     concern  jefferson   \n",
       "11     fatal    primarili     NaN      NaN  ...      embrac    kittita   \n",
       "12      fear     reinvent     NaN      NaN  ...  expenditur  klickitat   \n",
       "13  greatest       surviv     NaN      NaN  ...        held    lincoln   \n",
       "14    highli        typic     NaN      NaN  ...        ii.a     margin   \n",
       "15     induc          NaN     NaN      NaN  ...       month      mason   \n",
       "16      live          NaN     NaN      NaN  ...        onli      pacif   \n",
       "17    market          NaN     NaN      NaN  ...        them        phd   \n",
       "18   product          NaN     NaN      NaN  ...       total    prosser   \n",
       "19  threaten          NaN     NaN      NaN  ...      window     vallei   \n",
       "\n",
       "               0404     0408          0419          0423       0428      0437  \\\n",
       "0             ceic4   amount         crisi            80       16th       210   \n",
       "1             cific     bill         cross          aco√¢       1993     67756   \n",
       "2         communitv    coast           cut         deliv       3832      attn   \n",
       "3             defin   diabet        diseas        disast        384   biggest   \n",
       "4                 f    equip        disord         field      41863   cheyenn   \n",
       "5              fohc     exam         futur         learn     alfero    counti   \n",
       "6                ny       ey           mix         natur     andrew     elast   \n",
       "7                tk  florida        opioid          next        cah    embrac   \n",
       "8   www.chcanys.org     foot  particularli           now      chair    franci   \n",
       "9              york    invok      substanc        opioid     charli  frontier   \n",
       "10              NaN      nor           NaN         peopl     coburn     kansa   \n",
       "11              NaN   normal           NaN          plai     jennif     kelli   \n",
       "12              NaN      pcp           NaN       qualifi      keith    mechan   \n",
       "13              NaN   render           NaN        retain   lundblad        mr   \n",
       "14              NaN    retir           NaN  successfulli  mackinnei     order   \n",
       "15              NaN      NaN           NaN       suffici    mcbride  pottorff   \n",
       "16              NaN      NaN           NaN     transform    mueller    situat   \n",
       "17              NaN      NaN           NaN       triniti     object        st   \n",
       "18              NaN      NaN           NaN         trust       ph.d    street   \n",
       "19              NaN      NaN           NaN             √Ø    timothi         w   \n",
       "\n",
       "       0438          0467  \n",
       "0   baptist          0001  \n",
       "1   disagre          0101  \n",
       "2      foot           107  \n",
       "3      give  206.216.2541  \n",
       "4       NaN           445  \n",
       "5       NaN            45  \n",
       "6       NaN         along  \n",
       "7       NaN  association√¢  \n",
       "8       NaN       assumpt  \n",
       "9       NaN        barton  \n",
       "10      NaN            dc  \n",
       "11      NaN          down  \n",
       "12      NaN       enrolle  \n",
       "13      NaN        fiscal  \n",
       "14      NaN        fragil  \n",
       "15      NaN         front  \n",
       "16      NaN            fy  \n",
       "17      NaN             g  \n",
       "18      NaN     jacquelin  \n",
       "19      NaN   jacquelineb  \n",
       "\n",
       "[20 rows x 94 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrule = []\n",
    "for x in list(termvecs.values()):\n",
    "    for y in x:\n",
    "        if (y in content):\n",
    "            pass\n",
    "        else:\n",
    "            nrule.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nrule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrule = list(set(nrule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kaleb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in nrule:\n",
    "#     for sys in wordnet.synsets(i):\n",
    "#         for l in sys.lemmas():\n",
    "#             print(l.name())\n",
    "#         print(\"-----------------------------------{}-----------------------------------\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i in nrule:\n",
    "    synonym_list = []\n",
    "    for sys in wordnet.synsets(i):\n",
    "        for l in sys.lemmas():\n",
    "            synonym_list.append(l.name())\n",
    "    if(len(synonym_list) !=0):\n",
    "        synonym_dict[i] = list(set(synonym_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the,man,in,the,iron,mask => the target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li = ['the', 'man', 'in', 'the', 'iron', 'mask']\n",
    "rule = \",\".join(li) + ' => '+'the target'+ '\\n'\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = ''\n",
    "for i in nrule:\n",
    "    synonym_list = []\n",
    "    for sys in wordnet.synsets(i):\n",
    "        for l in sys.lemmas():\n",
    "            synonym_list.append(l.name())\n",
    "    if(len(synonym_list) !=0):\n",
    "        synonym_d = list(set(synonym_list))\n",
    "        rule = rule + ', '.join(synonym_d) + ' => ' + i + '\\n'\n",
    "fi = open('newsyn.txt', 'w')\n",
    "fi.write(rule)\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'president, chair, chairwoman, chairperson, chairman => chairman\\nAugusta, capital_of_Maine => augusta\\nSouth, southward, due_south, S, Confederacy, south, Confederate_States_of_America, Confederate_States, in_the_south, to_the_south, Dixieland, Dixie => south\\nKY, Bluegrass_State, Kentucky => ky\\nflyer, broadside, orbitual, broadsheet, throwaway, round, handbill, rotary, flier, circular, bill => circular\\nRichmond, capital_of_Virginia => richmond\\npsychiatrist, shrink, head-shrinker => psychiatrist\\nAmerican_language, American, American_English => american\\nfinger, palpate, spirit, flavour, flavor, experience, find, sense, tone, tactile_property, look, feel, feeling, smell => feel\\nUnion, northerly, north, magnetic_north, Second_Earl_of_Guilford, compass_north, N, Frederick_North, northwards, northward, due_north, North => north\\nmemorandum, memo, memoranda => memorandum\\nreinvent => reinvent\\nstandard, banner, streamer => banner\\nsmall_fry, minor, youngster, tyke, tiddler, tike, nestling, nipper, fry, shaver, baby, kid, child => child\\naerodynamic_lift, reverse, purloin, revoke, cosmetic_surgery, nobble, nip_and_tuck, rear, elevator, cabbage, countermand, plagiarise, elevate, filch, bring_up, wind, rhytidectomy, arise, rise, face-lift, snarf, plagiarize, pinch, get_up, face_lifting, swipe, uprise, pilfer, vacate, annul, ski_lift, heave, lift, rustle, rhytidoplasty, go_up, come_up, sneak, rescind, repeal, elevation, raising, airlift, raise, facelift, hoist, hook, face_lift, overturn, move_up, abstract, ski_tow => lift\\nCalluna_vulgaris, Scots_heather, ling, broom, sweep, heather => broom\\nsubscript, inferior, substandard, deficient => inferior\\nbirthing, parentage, have, nativity, giving_birth, parturition, deliver, nascence, bear, nascency, birth, give_birth => birth\\ncount_on, predict, foretell, auspicate, estimate, augur, portend, reckon, figure, foreshadow, omen, prefigure, prognosticate, presage, bode, prognosis, forecast, calculate, betoken => forecast\\nTexas, Lone-Star_State, TX => tx\\nangel_dust, health_care_provider, PCP, primary_care_provider, phencyclidine_hydrochloride, phencyclidine, caregiver, health_professional => pcp\\nretrieve, remember, reckon, call_back, imagine, mean, recall, believe, think, cogitate, recollect, call_up, conceive, cerebrate, opine, intend, consider, guess, suppose => think\\nUS, United_States_of_America, America, U.S., U.S.A., United_States, the_States, USA => america\\nWorth, deserving, worth, Charles_Frederick_Worth => worth\\nmissed, suffer, fall_behind, misplace, helpless, drop_off, bemused, deep_in_thought, miss, doomed, lose, recede, mazed, confused, confounded, baffled, fall_back, disoriented, mixed-up, lost, preoccupied, turn_a_loss, at_sea, bewildered, befuddled, mislay => lost\\nsilo => silo\\nsubdue, conquer, bottle_up, suppress, curb, stamp_down, inhibit => inhibit\\nslide, seashore, coast, sea-coast, seacoast, glide => coast\\nfrontier => frontier\\nmanaging_director, manager, film_director, music_director, theater_director, theatre_director, conductor, director => director\\nhalting, mettlesome, game, gritty, stake, gimpy, plot, punt, bet_on, gamey, spirited, back, gage, spunky, halt, lame, crippled, biz, gamy, secret_plan => game\\nshield, harbour, entertain, hold, seaport, harbor, nurse, haven => harbor\\nportfolio => portfolio\\navenue, boulevard => boulevard\\nsocietal, social, sociable, mixer => social\\nMN, Gopher_State, Minnesota, North_Star_State => minnesota\\ncard, control_board, dining_table, circuit_board, add-in, board, table, gameboard, plug-in, instrument_panel, display_panel, circuit_card, room, control_panel, panel, display_board, plank, get_on => board\\nPresident_Lincoln, President_Abraham_Lincoln, Lincoln, capital_of_Nebraska, Abraham_Lincoln => lincoln\\nattack_aircraft_carrier, mailman, carrier_wave, letter_carrier, newsboy, bearer, aircraft_carrier, immune_carrier, common_carrier, toter, mail_carrier, postman, flattop, carrier => carrier\\ndawn, sunrise, break_of_the_day, Aurora, morning, daybreak, cockcrow, first_light, sunup, aurora, dayspring, dawning, break_of_day => aurora\\nblog, web_log => blog\\nappear, seem, look => seem\\narmoured_personnel_carrier, APC, armored_personnel_carrier => apc\\nstand_out, surpass, excel => excel\\nheroic_poem, epic, larger-than-life, epos, epical, heroic, epic_poem => epic\\nveneration, revere, concern, fear, dread, fearfulness, care, fright, awe, venerate, reverence => fear\\nchiropodist, foot_doctor, podiatrist => podiatrist\\nbuy, dicker, steal, bargain, deal => bargain\\nbending, turn, crimp, stoop, flex, crouch, turn_away, flexure, Bend, crease, twist, deform, plication, bend, bow, deflect, bend_dexter, curve, fold, crook => bend\\nPrime_Minister, premier, PM, premiere, prime_minister, chancellor, prime => premier\\nfeat, tap, exploit, overwork, effort, work => exploit\\ngoddam, find_fault, pick, goddamn, fault, infernal, goddamned, damned, blamed, blessed, incrimination, charge, darned, blame, blasted, inculpation, deuced, rap, damn => blame\\nzone, district, territorial_dominion, territory, dominion => district\\nMason, James_Neville_Mason, Alfred_Edward_Woodley_Mason, Freemason, George_Mason, mason, stonemason, A._E._W._Mason, James_Mason => mason\\nSunshine_State, Florida, Everglade_State, FL => florida\\nfragmentize, break_up, shard, fragment, fragmentise, sherd => fragment\\nseamster, sartor, sew, tailor-make, orient, tailor, cut => tailor\\nroll, roster => roster\\ngrand, M, exalted, magisterial, marvelous, high-minded, thou, howling, terrific, wondrous, fantastic, luxurious, wonderful, tremendous, deluxe, yard, sumptuous, 1000, elevated, idealistic, marvellous, one_thousand, G, lordly, grand_piano, gilded, opulent, lofty, imposing, noble-minded, sublime, rattling, high-flown, rarefied, expansive, K, thousand, distinguished, rarified, heroic, princely, chiliad, august => grand\\nphenomenon => phenomenon\\nneurologist, brain_doctor => neurologist\\nsex_act, coitus, US_Congress, copulation, U.S._Congress, sexual_congress, United_States_Congress, intercourse, congress, Congress, relation, sexual_intercourse, carnal_knowledge, coition, sexual_relation => congress\\nrenovation, overhaul, modernize, pass, overtake, service, redevelopment, inspection_and_repair, modernise => overhaul\\nBritish_shilling, tail, bob, bobfloat, bobber, bobsled, shilling, cork, curtsy, bobtail, bobsleigh, dock => bob\\ncouncil => council\\nuncertainty, incertitude, question, dubiousness, doubtfulness, dubiety, doubt => doubt\\nPhD, Ph.D. => phd\\nKansa, Kansas => kansa\\nchurch, church_service, church_building, Christian_church => church\\nhyperlink => hyperlink\\ncan, lavatory, John, John_the_Divine, trick, whoremonger, whoremaster, Gospel_According_to_John, St._John_the_Apostle, lav, King_John, Saint_John_the_Apostle, Saint_John, John_Lackland, John_the_Evangelist, john, toilet, privy, bathroom, St._John => john\\ngent, fella, lad, companion, buster, cuss, familiar, associate, fellow, boyfriend, swain, feller, bloke, confrere, chap, comrade, colleague, blighter, mate, dude, young_man, beau => fellow\\npresident, moderate, professorship, chairwoman, chair, hot_seat, lead, chairperson, chairman, death_chair, electric_chair => chair\\nSecond_Adventist, Adventist => adventist\\nBaptist => baptist\\nchasm => chasm\\nangina, angina_pectoris => angina\\ntipple, drawing, order_of_payment, draft, outline, muster_in, blueprint, draft_copy, muster, draught, swig, rough_drawing, gulp, potation, enlist, selective_service, bill_of_exchange, conscription => draft\\nmayonnaise, mayo => mayo\\nSt._Andrew, Saint_Andrew, Andrew, Saint_Andrew_the_Apostle => andrew\\n13th, thirteenth => 13th\\nJefferson, Thomas_Jefferson, President_Jefferson => jefferson\\nfacsimile_machine, fax, facsimile, telefax => fax\\nfamily_line, tribe, kinfolk, ethnic_music, folk, folks, folk_music, family, common_people, sept, kinsfolk, phratry => folk\\nYork, House_of_York => york\\nNebraska, Cornhusker_State, NE => nebraska\\nworld, planetary, spheric, orbicular, spherical, global, globose, world-wide, ball-shaped, worldwide, globular => global\\nbounteous, cock-a-hoop, fully_grown, full-grown, bragging, liberal, vainglorious, grown, large, big, prominent, heavy, self-aggrandizing, expectant, great, magnanimous, bountiful, bighearted, boastful, enceinte, freehanded, with_child, grownup, adult, giving, crowing, swelled, bad, braggy, handsome, braggart, openhanded, gravid, self-aggrandising => biggest\\neditorial, newspaper_column, tower, chromatography_column, column, pillar => column\\nreligion, faith, religious_belief, organized_religion, trust => faith\\nblueness, blue_angel, spicy, drear, dreary, gentle, sorry, profane, grim, blueing, dark, low, Amytal, downhearted, risque, dismal, gloomy, blasphemous, patrician, blue_sky, down_in_the_mouth, dingy, disconsolate, blue_devil, bluing, blueish, down, downcast, gamey, puritanic, dispirited, low-spirited, aristocratical, racy, drab, blue, naughty, depressed, amobarbital_sodium, puritanical, blue_air, bluish, wild_blue_yonder, gamy, blue-blooded, aristocratic, juicy => blue\\nfocus, punctuate, tenseness, stress, accentuate, try, accent, emphasis, emphasize, emphasise, tension, strain => stress\\ngriffon, griffin, gryphon => griffin\\nmanual_of_arms, manual => manual\\nthreaten, jeopardise, endanger, jeopardize, menace, peril, imperil => threaten\\nArmin, Arminius, Hermann => hermann\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()\n",
    "answer = dictionary.synonym('kill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(answer)\n",
    "\n",
    "# the use case of the comment problem statement and architecture of the comment \n",
    "# the architecture of the momemntts.\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (type(answer) == list):\n",
    "#     print('the answer is: ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in nrule:\n",
    "    answer = dictionary.synonym(i,True)\n",
    "    count +=1\n",
    "    if (type(answer) == list):\n",
    "        count +=1\n",
    "#         print(answer)\n",
    "#         print('This is shte numner you are looking for', count)\n",
    "    if (count > 10):\n",
    "        break;\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
