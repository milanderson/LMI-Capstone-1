{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Splitting & ElasticSearch Uploads, Queries\n",
    "### LMI Capstone Team\n",
    "### Summer Chambers | Steve Morris | Kaleb Shikur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection, ElasticsearchException\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests #gets urls\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 173.79.72.92, port 9200\n",
    "# host = '173.79.72.92'\n",
    "endpoint = 'https://search-lmi-capstone-2-525zkk33t4z5iy6ozqd63ctgmq.us-east-1.es.amazonaws.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'eb7b3348d3c34ce7dc22f263930c51ad', 'cluster_name': '846033058400:lmi-capstone-2', 'cluster_uuid': 'QzTffcNgStmet053IRSP2w', 'version': {'number': '7.9.1', 'build_flavor': 'oss', 'build_type': 'tar', 'build_hash': 'unknown', 'build_date': '2020-11-03T09:54:32.349659Z', 'build_snapshot': False, 'lucene_version': '8.6.2', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "#es = Elasticsearch(endpoint, timeout = 45)\n",
    "es = Elasticsearch(endpoint, timeout=600, max_retries=2, retry_on_timeout=True)\n",
    "\n",
    "\n",
    "\n",
    "print(es.info())\n",
    "\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[{'host': host, 'port': 443}],\n",
    "#     http_auth=auth,\n",
    "#     use_ssl=True,\n",
    "#     verify_certs=True,\n",
    "#     connection_class=RequestsHttpConnection\n",
    "# )\n",
    "# print(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Rule Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/Rule/CMS-2018-0101-0001.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdict = {'a2':['2. proposals for modified participation options under 5-year agreement periods', '3. creating a basic track with glide path to performance-based risk'], \\\n",
    "     'a3':['3. creating a basic track with glide path to performance-based risk', '4. permitting annual participation elections'], \\\n",
    "    'a4b':['b. proposals for permitting election of differing levels of risk within the basic track\\'s glide path', 'c. proposals for permitting annual election of beneficiary assignment methodology'], \\\n",
    "    'a4c':['c. proposals for permitting annual election of beneficiary assignment methodology', '5. determining participation options based on medicare ffs revenue and prior participation '], \\\n",
    "    'a5b':['b. differentiating between low revenue acos and high revenue acos', 'c. determining participation options based on prior participation of aco legal entity and aco participants'], \\\n",
    "    'a5c':['c. determining participation options based on prior participation of aco legal entity and aco participants', 'd. monitoring for financial performance'], \\\n",
    "    'a5d': ['d. monitoring for financial performance', '6. requirements for aco participation in two-sided models'], \\\n",
    "    'a6b': ['b. election of msr/mlr by acos', 'c. aco repayment mechanisms'], \\\n",
    "    'a6c': ['c. aco repayment mechanisms', 'd. advance notice for and payment consequences of termination '], \\\n",
    "    'a6d2': ['(2) proposals for advance notice of voluntary termination', '(3) proposals for payment consequences of termination'], \\\n",
    "    'a6d3': ['(3) proposals for payment consequences of termination', '7. participation options for agreement periods beginning in 2019'], \\\n",
    "    'a7b': ['b. methodology for determining financial and quality performance for the 6-month performance years during 2019', 'c. applicability of program policies to acos participating in a 6-month performance year'], \\\n",
    "    'a7c': ['c. applicability of program policies to acos participating in a 6-month performance year', 'b. fee-for-service benefit enhancements'], \\\n",
    "    'b2a': ['a. shared savings program snf 3-day rule waiver', 'b. billing and payment for telehealth services'], \\\n",
    "    'b2b': ['b. billing and payment for telehealth services', 'c. providing tools to strengthen beneficiary engagement'], \\\n",
    "    'c2': ['2. beneficiary incentives', '3. empowering beneficiary choice'], \\\n",
    "    'c3a': ['3. empowering beneficiary choice', 'b. beneficiary opt-in based assignment methodology'], \\\n",
    "    'c3b': ['b. beneficiary opt-in based assignment methodology', 'd. benchmarking methodology refinements'],  \\\n",
    "    'd2': ['2. risk adjustment methodology for adjusting historical benchmark each performance year', '3. use of regional factors when establishing and resetting acos\\' benchmarks'], \\\n",
    "    'd3b': ['b. proposals to apply regional expenditures in determining the benchmark for an aco\\'s first agreement period', 'c. proposals for modifying the regional adjustment'], \\\n",
    "    'd3c': ['c. proposals for modifying the regional adjustment', 'd. proposals for modifying the methodology for calculating growth rates used in establishing, resetting, and updating the benchmark'], \\\n",
    "    'd3d': ['d. proposals for modifying the methodology for calculating growth rates used in establishing, resetting, and updating the benchmark', '4. technical changes to incorporate references to benchmark rebasing policies'], \\\n",
    "    'd4': ['4. technical changes to incorporate references to benchmark rebasing policies', 'e. updating program policies'], \\\n",
    "    'e2': ['2. revisions to policies on voluntary alignment', '3. revisions to the definition of primary care services used in beneficiary assignment'], \\\n",
    "    'e3': ['3. revisions to the definition of primary care services used in beneficiary assignment', '4. extreme and uncontrollable circumstances policies for the shared savings program'], \\\n",
    "    'e4': ['4. extreme and uncontrollable circumstances policies for the shared savings program', '5. program data and quality measures'], \\\n",
    "    'e5':['5. program data and quality measures', '6. promoting interoperability'], \\\n",
    "    'e6':['6. promoting interoperability', '7. coordination of pharmacy care for aco beneficiaries'], \\\n",
    "    'e7':['7. coordination of pharmacy care for aco beneficiaries', 'f. applicability of proposed policies to track 1+ model acos'], \\\n",
    "    'f2':['2. unavailability of application cycles for entry into the track 1+ model in 2019 and 2020', '3. applicability of proposed policies to track 1+ model acos through revised program regulations or revisions to track 1+ model participation agreements'], \\\n",
    "    'f3':['3. applicability of proposed policies to track 1+ model acos through revised program regulations or revisions to track 1+ model participation agreements', 'g. summary of proposed timing of applicability']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_headers(rule_url, startdict):\n",
    "\n",
    "    alltxt = requests.get(rule_url).text.lower()#.encode('unicode_escape').decode() #encodes like raw strings\n",
    "    \n",
    "    #Isolate Section 2\n",
    "    initialsplit = alltxt.split(\"ii. provisions of the proposed regulations\") #split before section 2\n",
    "    sec2andon = initialsplit[1] #choose latter half\n",
    "    sec2list = sec2andon.split(\"iii. collection of information requirements\") #split before section 3\n",
    "    splitlist = sec2list[0] #choose first half\n",
    "    \n",
    "    rulechunks = []\n",
    "    \n",
    "    for key, value in startdict.items():    \n",
    "       splitlist = splitlist.split(value[0]) #split on start of desired section\n",
    "       split_further = splitlist[1].split(value[1]) #split again on start of undesired section\n",
    "       rulechunks.append({\"section\": key, \"text\": (value[0]+split_further[0])}) #choose only first half to upload to dict\n",
    "       splitlist = splitlist[1] #choose second half to prepare for next split\n",
    "\n",
    "    return rulechunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_header_split = splitRule_headers(rule_url, startdict)\n",
    "headers_id_list = [doc[\"section\"] for doc in test_header_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_line_hybrid(rule_url):\n",
    "    new_rule_chunks = []\n",
    "    chunks = splitRule_headers(rule_url, startdict)\n",
    "    for doc in chunks:\n",
    "        paragraphs = doc[\"text\"].split('\\r\\n')\n",
    "        #add new lines while under 6000 characters\n",
    "        for i in range(len(paragraphs) - 1):\n",
    "            while i < (len(paragraphs)-1) and len(paragraphs[i]) < 6000:\n",
    "                paragraphs[i] += paragraphs[i+1]\n",
    "                del(paragraphs[i+1])\n",
    "        for i in range(len(paragraphs)):\n",
    "            new_rule_chunks.append({\"section\": doc[\"section\"]+str(i), \"text\": paragraphs[i]})\n",
    "    return new_rule_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = splitRule_line_hybrid(rule_url)\n",
    "lengths = {chunk[\"section\"]: len(chunk[\"text\"]) for chunk in result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Rule Splits to ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesplit_toES(rulechunks, es_index):\n",
    "    for chunk in rulechunks:\n",
    "            res = es.index(index=es_index, id=chunk[\"section\"], body=chunk, doc_type='_doc')\n",
    "            es.indices.refresh(index=es_index)\n",
    "    print(\"Last id uploaded:\", chunk[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_1shard = splitRule_headers(rule_url)\n",
    "upload_1shard = rulesplit_toES(rulesplit_1shard, \"headers_1shard2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f31\n"
     ]
    }
   ],
   "source": [
    "rulesplit_1shard = splitRule_line_hybrid(rule_url)\n",
    "upload_1shard = rulesplit_toES(rulesplit_1shard, \"hybrid_1shard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test1 = splitRule_headers(rule_url, startdict)\n",
    "test_upload1 = rulesplit_toES(rulesplit_test1, \"headers_broadsyn_custstop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test2 = splitRule_headers(rule_url, startdict)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"headers_narrowsyn_custstop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f31\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test2 = splitRule_line_hybrid(rule_url)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"hybrid_custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test2 = splitRule_headers(rule_url, startdict)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"headers_expsyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test2 = splitRule_headers(rule_url, startdict)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"headers_nosyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: f3\n"
     ]
    }
   ],
   "source": [
    "rulesplit_test2 = splitRule_headers(rule_url, startdict)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"headers_expsyn_comsyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##es.indices.refresh(index=\"index_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##es.indices.delete(index='sanity_check', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Comment Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/Comments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_comments(comment_url):\n",
    "    response = requests.get(comment_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    a_tags = soup.findAll(\"a\")\n",
    "    links = [tag[\"href\"] for tag in a_tags]\n",
    "    txt_links = [link for link in links if '.txt' in link]\n",
    "    comments = {}\n",
    "    for suffix in txt_links:\n",
    "        comments[suffix] = requests.get(comment_url+suffix).text.lower()\n",
    "        #print(f\"scraping comment {suffix}\")\n",
    "    print(f\"scraped {len(txt_links)} comments\")\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2018 = retrieve_comments(comment_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_lengths = {key: len(value) for key, value in comments2018.items()}\n",
    "sorted_comment_lengths = dict(sorted(comment_lengths.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2018 = {(key[14:20]): value for key, value in comments2018.items()}\n",
    "sorted_keys = sorted(list(comments2018.keys()))\n",
    "\n",
    "# now for each key in the list\n",
    "for i in range(len(comments2018)-1):\n",
    "    # get key at index i and key at index i+1 and compare them\n",
    "    if sorted_keys[i+1][0:4] == sorted_keys[i][0:4]:\n",
    "        comments2018[sorted_keys[i+1]] = comments2018[sorted_keys[i]] + comments2018[sorted_keys[i+1]]\n",
    "        del(comments2018[sorted_keys[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2018 = {key[0:4]:value for key, value in comments2018.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comments2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_json = json.dumps(comments2018)\n",
    "f = open('comments2018.json','w')\n",
    "f.write(comment_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid scraping comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments2018.json') as f:\n",
    "    comments2018 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate comments, comments less than 30 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0083': 'good luck everyone!',\n",
       " '0142': 'see attached file(s)',\n",
       " '0237': 'see attached file(s)\\n',\n",
       " '0270': 'see attached file(s)\\n',\n",
       " '0293': 'see attached file(s)',\n",
       " '0321': 'see attached file(s)\\n\\n',\n",
       " '0324': 'see attachement\\n',\n",
       " '0329': 'see attached file(s)\\n',\n",
       " '0342': 'see attached file(s)\\n',\n",
       " '0447': 'see attached file(s)'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_comments2018 = {key: val for key, val in comments2018.items() if len(val) >= 30}\n",
    "short_ones = {key: val for key, val in comments2018.items() if len(val) < 30}\n",
    "list_reduced_comments2018 = list(reduced_comments2018.values())\n",
    "len(reduced_comments2018)\n",
    "short_ones #these seem okay to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeDuper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = getDupes(list_reduced_comments2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(duplicates))\n",
    "#duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupdict = {}\n",
    "for i, dup in enumerate(duplicates):\n",
    "    dupdict[i] = [list_reduced_comments2018[idx][0:120] for idx in dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dupdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_deleted = []\n",
    "for num, duplist in enumerate(duplicates):\n",
    "    for idx, comment in enumerate(list_reduced_comments2018):\n",
    "        if idx in duplist[:-1]:\n",
    "            tb_deleted.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tb_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_comments2018 = {key:value for key, value in reduced_comments2018.items() if value not in tb_deleted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_comments2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(unique_comments2018)\n",
    "f = open('unique_comments2018.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid scraping comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_comments2018.json') as f:\n",
    "    unique_comments2018 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up longer comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_comments = {key:value for key, value in unique_comments2018.items() if len(value) > 5000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = unique_comments2018.copy()\n",
    "for key, value in long_comments.items():\n",
    "    paragraphs = value.split('\\n')\n",
    "    for i in range(len(paragraphs) - 1):\n",
    "        while i < (len(paragraphs) - 1) and len(paragraphs[i]) < 4800:\n",
    "            paragraphs[i] += paragraphs[i+1]\n",
    "            del(paragraphs[i+1])\n",
    "    for i in range(len(paragraphs)):\n",
    "        expanded[key+'_'+str(i)] = paragraphs[i]\n",
    "expanded = {key:value for key, value in expanded.items() if key not in list(long_comments.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{key:len(value) for key, value in expanded.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove \\r, \\n, \\s, and any weird or non-ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = {key:value.replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\s\", \" \") for key, value in expanded.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in expanded.items():\n",
    "    expanded[key] = ''.join(c for c in value if c in string.printable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(expanded)\n",
    "f = open('expanded.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .json (avoid scraping comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('expanded.json') as f:\n",
    "    expanded = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing other basic API Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if document_id exists in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.exists(index=\"headers\", id=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View term vectors for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'headers',\n",
       " '_type': '_doc',\n",
       " '_id': '6',\n",
       " '_version': 1,\n",
       " 'found': True,\n",
       " 'took': 0,\n",
       " 'term_vectors': {}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.termvectors(index=\"headers\", id=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an explanation for a query's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.explain(index=\"hybrid_6000\", id=6, body={\"query\": test_comment0002_query}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single query\n",
    "def ES_search(es_index, querydict, search_type=None):\n",
    "    if search_type:\n",
    "        search = es.search(index=es_index, doc_type=\"_doc\", body={\"query\": querydict}, search_type=search_type, size=5)\n",
    "    else:\n",
    "        search = es.search(index=es_index, doc_type=\"_doc\", body={\"query\": querydict})\n",
    "    test_dict = {}\n",
    "    if search['hits']['hits'] != []:\n",
    "        for h in search['hits']['hits']:\n",
    "            test_dict[h['_id']]=h['_score']\n",
    "    return test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a few types of queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"Simple Query String\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment0002_query = {\"simple_query_string\": {\"query\": expanded['0002']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a4c': 151.79832,\n",
       " 'a6c': 148.1676,\n",
       " 'a2': 77.816055,\n",
       " 'a5b': 69.46873,\n",
       " 'a5c': 63.691624,\n",
       " 'a3': 62.509632,\n",
       " 'a5d': 59.190556,\n",
       " 'c3b': 57.04912,\n",
       " 'd3d': 56.666798,\n",
       " 'e4': 55.296684}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"headers_standard\", test_comment0002_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"More Like This\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_test0002 = {\"more_like_this\": {\"fields\": [\"text\"], \"like\": expanded[\"0004\"]}}#, \"min_term_freq\": 1, \"max_query_terms\": 30}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a7c': 4.9438677,\n",
       " 'a4c': 4.86566,\n",
       " 'a6c': 4.861052,\n",
       " 'a6b': 4.762745,\n",
       " 'a5b': 4.6482067,\n",
       " 'e3': 4.563411,\n",
       " 'a6d3': 4.2192745,\n",
       " 'a3': 4.1510067,\n",
       " 'a4b': 4.104784,\n",
       " 'd3d': 3.6692913}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"headers_standard\", mlt_test0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"Match\" or \"Match_Phrase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_test0002 = {\"match\" : {\"text\" : expanded[\"0002\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a4c': 152.92398,\n",
       " 'a6c': 149.1905,\n",
       " 'a2': 80.02064,\n",
       " 'a5b': 70.87577,\n",
       " 'a5c': 63.691628,\n",
       " 'a3': 62.509632,\n",
       " 'a5d': 59.190556,\n",
       " 'c3b': 57.04912,\n",
       " 'd3d': 56.666798,\n",
       " 'e4': 55.296684}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"headers_standard\", match_test0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Bool, should\" and \"Match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_test = {\"bool\":{\"should\":[{\"match\":{\"text\":{\"query\":expanded[\"0002\"]}}}]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a6c75': 95.89467,\n",
       " 'a20': 90.73644,\n",
       " 'e51': 89.76659,\n",
       " 'a4c105': 86.93875,\n",
       " 'a6c42': 81.72023,\n",
       " 'a4c72': 80.15328,\n",
       " 'a4c106': 77.97759,\n",
       " 'a6c76': 75.50844,\n",
       " 'a6d30': 73.30347,\n",
       " 'a4c53': 72.953026}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"hybrid_reindex\", match_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Queries in One, Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"query\":\n",
    "{  \n",
    "    \"bool\":{  \n",
    "        \"should\":[  \n",
    "            {  \n",
    "                \"match\":{  \n",
    "                    \"title\":{  \n",
    "                        \"query\":\"cat\",\n",
    "                        \"boost\":2\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {  \n",
    "                \"match\":{  \n",
    "                    \"content\":{  \n",
    "                        \"query\":\"cat\",\n",
    "                        \"boost\":2\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Many Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es.indices.refresh(index=?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_large_query(comment_dict, es_index):\n",
    "    results = {}\n",
    "    for key, value in comment_dict.items():\n",
    "        query = {\"match\" : {\"text\" : value}}\n",
    "        try:\n",
    "            search1 = ES_search(es_index, query, 'dfs_query_then_fetch')\n",
    "        except ElasticsearchException as es1:\n",
    "            print(es1)\n",
    "            es.indices.refresh(index=es_index)\n",
    "            continue\n",
    "        results[key] = {section:score for section, score in search1.items()}\n",
    "        time.sleep(3)\n",
    "        es.indices.refresh(index=es_index)\n",
    "        print(key, end=' ')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_comments = {\"matches_a2\": \"2. proposals for modified participation options under 5-year agreement periods\\r\\n     in developing the proposed policies described in this section, we considered a number of factors related to the program's current participation options in light of the program's financial results and stakeholders' feedback on program design, including the following.\\r\\n     first, we considered the program's existing policy allowing acos up to 6 years of participation in a one-sided model. we have found that the policy has shown limited success in encouraging acos to advance to performance-based risk. by the fifth year of implementing the program, only about 18 percent of the program's participating acos are under a two-sided model, over half of which are participating in the track 1+ model (see table 1).\\r\\n     as discussed in detail in the regulatory impact analysis (see section iv. of this proposed rule), our experience with the program indicates that acos in two-sided models generally perform better than acos that participate under a one-sided model. for example, for performance year 2016, about 68 percent of shared savings program acos in two-sided models (15 of 22 acos) shared savings compared to 29 percent of track 1 acos. for performance year 2015, prior to the first year of track 3, one of the three remaining track 2 acos shared savings, while about 30 percent of track 1 acos (118 of 389 acos) shared savings. for performance year 2014, two of the three remaining track 2 acos shared savings while about 25 percent of track 1 acos (84 of 330 acos) shared savings. in the program's first year, concluding december 31, 2013, 40 percent of track 2 acos (2 of 5 acos) compared to 23 percent of track 1 acos (50 of 215 acos) shared savings. see shared savings program accountable care organization public use files, available at https://www.cms.gov/research-statistics-data-and-systems/downloadable-public-use-files/sspaco/index.html. these observations, in combination with participation trends that show acos prefer to remain in track 1 for a second 3-year agreement period, suggests that a requirement for acos to more rapidly transition to performance-based risk could be effective in creating incentives for acos to more quickly meet the program's goals.     https://www.cms.gov/research-statistics-data-and-systems/downloadable-public-use-files/sspaco/index.html.\\r\\n     the program's current design lacks a sufficiently incremental progression to performance-based risk, the need for which is evidenced by robust participation in the new track 1+ model. we believe a significant issue that contributes to some acos' reluctance to participate in track 2 or track 3 is that the magnitude of potential losses is very high compared to the aco's degree of control over the total medicare parts a and b ffs expenditures for the aco's assigned beneficiaries, particularly when its aco participants have relatively low total medicare parts a and b ffs revenue. we are encouraged by the interest in the track 1+ model as indicated by the 55 shared savings program acos participating in the model for the performance year beginning on january 1, 2018; the largest group of shared savings program acos to enter into performance-based risk for a given performance year to date. based on the number of acos participating in the track 1+ model for performance year 2018, a lower risk option appears to be important for track 1 acos with experience in the program seeking to transition to performance-based risk, as well as acos seeking to enter an initial agreement period in the program under a lower risk model.\\r\\n     interest in the track 1+ model suggests that the opportunity to participate in an advanced apm while accepting more moderate levels of risk (compared to track 2 and track 3) is an important financial model design for acos. allowing more manageable levels of risk within the shared savings program is an important pathway for helping organizations to gain experience with managing risk as well as participating in advanced apms under the quality payment program. the high uptake we have observed with the track 1+ model also suggests that the current design of track 1 may be unnecessarily generous since the track 1+ model has the same level of upside as track 1 but under which acos must also assume performance-based risk.\\r\\n     second, under the program's current design, cms lacks adequate tools to properly address acos with patterns of negative financial performance. track 1 acos are not liable for repaying any portion of their losses to cms, and therefore may have potentially weaker incentives to improve quality and reduce growth in ffs expenditures within the accountable care model. these acos may take advantage of the potential benefits of continued program participation (including the receipt of program data and the opportunity to enter into certain contracting arrangements with aco participants and aco providers/suppliers in connection with their participation in the shared savings program), without providing a meaningful benefit to the medicare program. acos under two-sided models may similarly benefit from program participation and seek to continue their participation despite owing shared losses.\\r\\n     third, differences in performance of acos indicate a pattern where low revenue acos outperformed high revenue acos. as discussed in the regulatory impact analysis (see section iv. of this proposed rule), we have observed a pattern of performance, across tracks and performance years, where low revenue acos show better average results compared to high revenue acos. we believe high revenue acos, which typically include hospitals, have a greater opportunity to control assigned beneficiaries' total medicare parts a and b ffs expenditures, as they coordinate a larger portion of the assigned beneficiaries' care across care settings, and have the potential to perform better than what has been demonstrated in performance trends from 2012 through 2016. we conclude that the trends in performance by high revenue acos in relation to their expected capacity to control growth in expenditures are indications that these acos' performance would improve through greater incentives, principally a requirement to take on higher levels of performance-based risk, and thus drive change in ffs utilization for their medicare ffs populations. this conclusion is further supported by our initial experience with the track 1+ model, for which our preliminary findings support the conclusion that the degree of control an aco has over expenditures for its assigned beneficiaries is an indication of the level of performance-based risk an aco is prepared to accept and manage, where control is determined by the relationship between aco participants' total medicare parts a and b ffs revenue and the total medicare parts a and b ffs expenditures for the aco's assigned beneficiaries. our experience with the track 1+ model has also shown that aco participants' total medicare parts a and b ffs revenue as a percentage of the total medicare parts a and b ffs expenditures of the assigned beneficiaries can serve as a proxy for aco composition (that is, whether the aco includes one or more institutional providers as an aco participant, and therefore is likely to control a greater share of medicare parts a and b ffs expenditures and to have greater ability to coordinate care across settings for its assigned beneficiaries).\\r\\n     fourth, permitting choice of level of risk and assignment methodology within an aco's agreement period would create redundancy in some participation options, and eliminating this redundancy would allow cms to streamline the number of tracks offered while allowing acos greater flexibility to design their participation to meet the needs of their organizations. acos and stakeholders have indicated a strong preference for maintaining an option to select preliminary prospective assignment with retrospective reconciliation as an alternative to prospective assignment for acos under performance-based risk within the shared savings program. we considered what would occur if we retained track 2 in addition to the enhanced track and offered a choice of prospective assignment and preliminary prospective assignment (see section ii.a.4.c. of this proposed rule) for both tracks. we believe that acos prepared to accept higher levels of benchmark-based risk would be more likely to enter the enhanced track (which allows the greatest risk and potential reward). this is suggested by participation statistics, where 8 acos are participating in track 2 compared to the 38 acos participating in track 3 as of january 1, 2018. we note that for agreement periods beginning in 2018, only 2 acos entered track 2, both of which had deferred renewal in 2017, while 4 acos entered track 3 (for their first or second agreement period). acos may be continuing to pick track 2 because of the preliminary prospective assignment methodology, and we would expect participation in track 2 to decline further if we finalize the proposal to allow a choice of assignment methodology in the enhanced track, since we would expect acos ready for higher risk (that is, a level of risk that is higher than the highest level of risk and potential reward under the proposed basic track) to prefer the enhanced track over track 2.\\r\\n     fifth, longer agreement periods could improve program incentives and support acos' transition into performance-based risk when coupled with changes to improve the accuracy of the program's benchmarking methodology. extending agreement periods for more than 3 years could provide more certainty over benchmarks and in turn give acos a greater chance to succeed in the program by allowing them more time to understand their performance, gain experience and implement redesigned care processes before rebasing of the aco's historical benchmark. shared savings program results show that acos tend to perform better the longer they remain in the program. further, under longer agreement periods, historical benchmarks would become more predictable, since the benchmark would continue to be based on the expenditures for beneficiaries who would have been assigned to the aco in the 3 most recent years prior to the start of the aco's agreement period (see 425.602(a) and 425.603(c)) and the benchmark would be risk adjusted and updated each performance year relative to benchmark year 3. however, a number of factors can affect the amount of the benchmark, and therefore its predictability, during the agreement period regardless of whether the agreement period spans 3 or 5 years, including: adjustments to the benchmark during the aco's agreement period resulting from changes in the aco's certified aco participant list and regulatory changes to the assignment methodology; as well as variation in the benchmark value that occurs each performance year as a result of annual risk adjustment to the aco's benchmark (425.602(a)(9) and 425.603(c)(10)) and annual benchmark updates (425.602(b) and 425.603(d)). further, as discussed in section ii.d of this proposed rule, we believe the proposed approach to incorporating factors based on regional ffs expenditures in establishing, adjusting and updating the benchmark beginning with the aco's first agreement period will result in more accurate benchmarks. this improved accuracy of benchmarks would mitigate the impact of the more generous updated benchmarks that could result in the later years of longer agreement periods.\\r\\n     in summary, taking these factors into consideration, we propose to redesign the program's participation options by discontinuing track 1, track 2 and the deferred renewal option, and instead offering two tracks that eligible acos would enter into for an agreement period of at least 5 years: (1) basic track, which would include an option for eligible acos to begin participation under a one-sided model and incrementally phase-in risk (calculated based on aco participant revenue and capped at a percentage of the aco's updated benchmark) and potential reward over the course of a single agreement period, an approach referred to as a glide path;\", \\\n",
    "                \"matches_none\": \"the quick brown fox jumps over the lazy dog\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_test0002 = {\"more_like_this\": {\"fields\": [\"text\"], \"like\": fake_comments[\"matches_a2\"], \"min_term_freq\": 1, \"max_query_terms\": 50}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2': 28.361528,\n",
       " 'a3': 27.738836,\n",
       " 'a5b': 26.990551,\n",
       " 'a5d': 24.768711,\n",
       " 'a7c': 23.503782,\n",
       " 'd2': 21.002817,\n",
       " 'a4c': 20.975582,\n",
       " 'a6c': 20.871943,\n",
       " 'e4': 20.871286,\n",
       " 'a6d3': 20.378096}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"headers_narrowsyn_custstop\", mlt_test0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches_a2 matches_none "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches_a2': {'a2': 962.5827,\n",
       "  'a4c': 771.5503,\n",
       "  'a6c': 722.64966,\n",
       "  'a5b': 621.0664,\n",
       "  'a3': 586.91016,\n",
       "  'a5c': 560.27325,\n",
       "  'c3b': 503.69507,\n",
       "  'e4': 453.04593,\n",
       "  'a7c': 425.9492,\n",
       "  'a6b': 418.6685},\n",
       " 'matches_none': {}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_large_query(fake_comments, \"headers_narrowsyn_custstop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0002': {'a6c': 108.97458,\n",
       "  'a4c': 107.97814,\n",
       "  'd3d': 82.54391,\n",
       "  'e5': 80.80219,\n",
       "  'a5c': 76.095146,\n",
       "  'd2': 74.08951,\n",
       "  'c3b': 73.13041,\n",
       "  'a5b': 70.770615,\n",
       "  'a2': 59.04697,\n",
       "  'c2': 58.028397},\n",
       " '0004': {'a4c': 57.26756,\n",
       "  'a6c': 56.25602,\n",
       "  'a5b': 48.102943,\n",
       "  'e4': 44.462315,\n",
       "  'a3': 40.867332,\n",
       "  'e5': 39.244144,\n",
       "  'c3b': 37.973938,\n",
       "  'a2': 36.74947,\n",
       "  'a5c': 36.44169,\n",
       "  'e6': 34.330204},\n",
       " '0005': {'e5': 220.57083,\n",
       "  'a4c': 210.88545,\n",
       "  'a6c': 202.52736,\n",
       "  'a5b': 197.70358,\n",
       "  'c3b': 136.87021,\n",
       "  'a5c': 125.184715,\n",
       "  'd3d': 120.47933,\n",
       "  'c2': 120.198006,\n",
       "  'a2': 107.514725,\n",
       "  'd2': 103.19107}}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on dictionary of 3 key/value\n",
    "dict_first3 = {}\n",
    "for key in list(expanded.keys())[0:3]:\n",
    "    dict_first3[key] = expanded[key]\n",
    "\n",
    "run_large_query(dict_first3, \"headers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEADERS CUSTOM Unique/clean comment Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "header_custom_results = run_large_query(expanded, \"headers_custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(header_custom_results)\n",
    "f = open('match_header_custom_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEADERS CUSTOM Unique/clean comment Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "headers_broadsyn_custstop_results = run_large_query(expanded, \"headers_broadsyn_custstop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(headers_broadsyn_custstop_results)\n",
    "f = open('headers_broadsyn_custstop_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYBRID CUSTOM Unique/clean comment Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "hybrid_custom_results = run_large_query(expanded, \"hybrid_custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(hybrid_custom_results)\n",
    "f = open('match_hybrid_custom_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "headers_custom_results = run_large_query(expanded, \"headers_expsyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(headers_custom_results)\n",
    "f = open('headers_expsyn_basestop_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "headers_nosyn_basestop_results = run_large_query(expanded, \"headers_nosyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(headers_nosyn_basestop_results)\n",
    "f = open('headers_nosyn_basestop_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comment syn included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002 0004 0005 0006 0007 0008 0009 0010 0011 0016 0042 0077 0110 0115 0126 0157 0170 0174 0191 0195 0205 0209 0211 0221 0222 0226 0229 0233 0239 0240 0249 0253 0256 0261 0263 0265 0267 0271 0287 0297 0319 0331 0347 0360 0361 0362 0374 0376 0385 0399 0401 0404 0408 0419 0428 0437 0438 0467 0003_0 0003_1 0012_0 0012_1 0012_2 0012_3 0013_0 0013_1 0013_2 0013_3 0013_4 0013_5 0013_6 0013_7 0013_8 0013_9 0013_10 0013_11 0013_12 0014_0 0014_1 0081_0 0081_1 0138_0 0138_1 0138_2 0172_0 0172_1 0172_2 0172_3 0182_0 0182_1 0182_2 0189_0 0189_1 0190_0 0190_1 0190_2 0197_0 0197_1 0197_2 0197_3 0204_0 0204_1 0204_2 0204_3 0204_4 0204_5 0204_6 0204_7 0204_8 0207_0 0207_1 0208_0 0208_1 0208_2 0212_0 0212_1 0212_2 0212_3 0234_0 0234_1 0234_2 0241_0 0241_1 0241_2 0243_0 0243_1 0245_0 0245_1 0245_2 0245_3 0245_4 0245_5 0245_6 0245_7 0247_0 0247_1 0247_2 0247_3 0247_4 0247_5 0247_6 0254_0 0254_1 0254_2 0254_3 0254_4 0258_0 0258_1 0268_0 0268_1 0268_2 0301_0 0301_1 0301_2 0301_3 0301_4 0304_0 0304_1 0304_2 0304_3 0304_4 0308_0 0308_1 0308_2 0308_3 0308_4 0308_5 0308_6 0308_7 0308_8 0308_9 0308_10 0308_11 0308_12 0312_0 0312_1 0312_2 0312_3 0312_4 0322_0 0322_1 0322_2 0322_3 0322_4 0326_0 0326_1 0326_2 0326_3 0326_4 0326_5 0326_6 0326_7 0326_8 0326_9 0326_10 0336_0 0336_1 0346_0 0346_1 0346_2 0346_3 0346_4 0346_5 0346_6 0353_0 0353_1 0353_2 0353_3 0353_4 0353_5 0357_0 0357_1 0357_2 0357_3 0357_4 0357_5 0357_6 0357_7 0357_8 0357_9 0357_10 0383_0 0383_1 0386_0 0386_1 0386_2 0386_3 0386_4 0386_5 0386_6 0386_7 0386_8 0386_9 0386_10 0386_11 0386_12 0386_13 0386_14 0386_15 0386_16 0386_17 0386_18 0386_19 0386_20 0386_21 0386_22 0386_23 0386_24 0386_25 0386_26 0386_27 0423_0 0423_1 0423_2 0423_3 0423_4 0423_5 0423_6 "
     ]
    }
   ],
   "source": [
    "headers_expsyn_comsyn_basestop_results = run_large_query(expanded, \"headers_expsyn_comsyn_basestop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(headers_expsyn_comsyn_basestop_results)\n",
    "f = open('headers_expsyn_comsyn_basestop_results.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "termVectorBody = {\n",
    "  \"fields\" : [\"text\"],\n",
    "  \"term_statistics\" : True,\n",
    "  \"field_statistics\" : True,\n",
    "  \"offsets\" : False,\n",
    "  \"payloads\" : False,\n",
    "  \"positions\" : False,\n",
    "    \"filter\": {\n",
    "    \"max_num_terms\": 30,\n",
    "    \"min_term_freq\": 1,\n",
    "    \"min_doc_freq\": 28 ## 90% of documents\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "termvecs = dict()\n",
    "result = es.termvectors(index=\"headers_1shard\", id ='a2', body=termVectorBody)\n",
    "{'a2':list(result['term_vectors']['text']['terms'].keys())}\n",
    "for section in headers_id_list:\n",
    "    result = es.termvectors(index = \"headers_1shard\", id = section, body= termVectorBody)\n",
    "    termvecs[section] = list(result['term_vectors']['text']['terms'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'particip',\n",
       " '2',\n",
       " 'addit',\n",
       " '2019',\n",
       " 'share',\n",
       " 'provid',\n",
       " 'cm',\n",
       " 'perform',\n",
       " 'includ',\n",
       " 'beneficiari',\n",
       " 'year',\n",
       " 'rule',\n",
       " 'program',\n",
       " \"aco'\",\n",
       " 'propos',\n",
       " 'final',\n",
       " 'save',\n",
       " 'aco',\n",
       " 'subsequ',\n",
       " 'requir',\n",
       " 'establish',\n",
       " 'section',\n",
       " '3',\n",
       " 'appli']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = [value for key, value in termvecs.items()]\n",
    "common_words = list(set([word for list1 in common_words for word in list1]))\n",
    "common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "termVectorBody = {\n",
    "  \"fields\" : [\"text\"],\n",
    "  \"term_statistics\" : True,\n",
    "  \"field_statistics\" : True,\n",
    "  \"offsets\" : False,\n",
    "  \"payloads\" : False,\n",
    "  \"positions\" : False,\n",
    "    \"filter\": {\n",
    "    \"max_num_terms\": 10,\n",
    "    \"min_term_freq\": 1,\n",
    "    \"min_doc_freq\": 1,\n",
    "    \"max_doc_freq\": 27\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "termvecs = dict()\n",
    "result = es.termvectors(index=\"headers_1shard\", id ='a2', body=termVectorBody)\n",
    "{'a2':list(result['term_vectors']['text']['terms'].keys())}\n",
    "for section in headers_id_list:\n",
    "    result = es.termvectors(index = \"headers_1shard\", id = section, body= termVectorBody)\n",
    "    termvecs[section] = list(result['term_vectors']['text']['terms'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r boost_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4b</th>\n",
       "      <th>a4c</th>\n",
       "      <th>a5b</th>\n",
       "      <th>a5c</th>\n",
       "      <th>a5d</th>\n",
       "      <th>a6b</th>\n",
       "      <th>a6c</th>\n",
       "      <th>a6d2</th>\n",
       "      <th>a6d3</th>\n",
       "      <th>a7b</th>\n",
       "      <th>a7c</th>\n",
       "      <th>b2a</th>\n",
       "      <th>b2b</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3a</th>\n",
       "      <th>c3b</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3b</th>\n",
       "      <th>d3c</th>\n",
       "      <th>d3d</th>\n",
       "      <th>d4</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>agreement</td>\n",
       "      <td>base</td>\n",
       "      <td>agreement</td>\n",
       "      <td>adjust</td>\n",
       "      <td>assign</td>\n",
       "      <td>agreement</td>\n",
       "      <td>425.316</td>\n",
       "      <td>5,000</td>\n",
       "      <td>adjust</td>\n",
       "      <td>applic</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>assign</td>\n",
       "      <td>1834</td>\n",
       "      <td>1899</td>\n",
       "      <td>425.312</td>\n",
       "      <td>approach</td>\n",
       "      <td>adjust</td>\n",
       "      <td>agreement</td>\n",
       "      <td>adjust</td>\n",
       "      <td>assign</td>\n",
       "      <td>425.601</td>\n",
       "      <td>425.402</td>\n",
       "      <td>99304</td>\n",
       "      <td>affect</td>\n",
       "      <td>d</td>\n",
       "      <td>advanc</td>\n",
       "      <td>arrang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>base</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>agreement</td>\n",
       "      <td>base</td>\n",
       "      <td>base</td>\n",
       "      <td>action</td>\n",
       "      <td>assign</td>\n",
       "      <td>agreement</td>\n",
       "      <td>dai</td>\n",
       "      <td>agreement</td>\n",
       "      <td>agreement</td>\n",
       "      <td>agreement</td>\n",
       "      <td>bed</td>\n",
       "      <td>act</td>\n",
       "      <td>425.304</td>\n",
       "      <td>care</td>\n",
       "      <td>assign</td>\n",
       "      <td>agreement</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>aggreg</td>\n",
       "      <td>blend</td>\n",
       "      <td>425.603</td>\n",
       "      <td>act</td>\n",
       "      <td>99354</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>fill</td>\n",
       "      <td>apm</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>basic</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>elect</td>\n",
       "      <td>assign</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>agreement</td>\n",
       "      <td>b</td>\n",
       "      <td>assign</td>\n",
       "      <td>decis</td>\n",
       "      <td>date</td>\n",
       "      <td>assign</td>\n",
       "      <td>assign</td>\n",
       "      <td>dai</td>\n",
       "      <td>furnish</td>\n",
       "      <td>act</td>\n",
       "      <td>data</td>\n",
       "      <td>base</td>\n",
       "      <td>assign</td>\n",
       "      <td>expenditur</td>\n",
       "      <td>cap</td>\n",
       "      <td>by3</td>\n",
       "      <td>425.800</td>\n",
       "      <td>assign</td>\n",
       "      <td>care</td>\n",
       "      <td>circumst</td>\n",
       "      <td>http</td>\n",
       "      <td>cehrt</td>\n",
       "      <td>coordin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>defer</td>\n",
       "      <td>level</td>\n",
       "      <td>glide</td>\n",
       "      <td>base</td>\n",
       "      <td>ff</td>\n",
       "      <td>enter</td>\n",
       "      <td>corridor</td>\n",
       "      <td>mlr</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>end</td>\n",
       "      <td>effect</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>juli</td>\n",
       "      <td>hospit</td>\n",
       "      <td>l</td>\n",
       "      <td>incent</td>\n",
       "      <td>declin</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>histor</td>\n",
       "      <td>enrol</td>\n",
       "      <td>compon</td>\n",
       "      <td>add</td>\n",
       "      <td>care</td>\n",
       "      <td>code</td>\n",
       "      <td>determin</td>\n",
       "      <td>measur</td>\n",
       "      <td>clinician</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>level</td>\n",
       "      <td>limit</td>\n",
       "      <td>level</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>high</td>\n",
       "      <td>model</td>\n",
       "      <td>financi</td>\n",
       "      <td>model</td>\n",
       "      <td>care</td>\n",
       "      <td>notic</td>\n",
       "      <td>liabl</td>\n",
       "      <td>calendar</td>\n",
       "      <td>list</td>\n",
       "      <td>preliminarili</td>\n",
       "      <td>origin</td>\n",
       "      <td>item</td>\n",
       "      <td>inform</td>\n",
       "      <td>care</td>\n",
       "      <td>cap</td>\n",
       "      <td>incorpor</td>\n",
       "      <td>percent</td>\n",
       "      <td>counti</td>\n",
       "      <td>adjust</td>\n",
       "      <td>clinician</td>\n",
       "      <td>cpt</td>\n",
       "      <td>disast</td>\n",
       "      <td>misus</td>\n",
       "      <td>criterion</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>model</td>\n",
       "      <td>loss</td>\n",
       "      <td>path</td>\n",
       "      <td>period</td>\n",
       "      <td>low</td>\n",
       "      <td>period</td>\n",
       "      <td>monitor</td>\n",
       "      <td>msr</td>\n",
       "      <td>month</td>\n",
       "      <td>product</td>\n",
       "      <td>loss</td>\n",
       "      <td>determin</td>\n",
       "      <td>month</td>\n",
       "      <td>prospect</td>\n",
       "      <td>practition</td>\n",
       "      <td>m</td>\n",
       "      <td>medicar</td>\n",
       "      <td>claim</td>\n",
       "      <td>hcc</td>\n",
       "      <td>methodolog</td>\n",
       "      <td>region</td>\n",
       "      <td>factor</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>design</td>\n",
       "      <td>evalu</td>\n",
       "      <td>extrem</td>\n",
       "      <td>opioid</td>\n",
       "      <td>elig</td>\n",
       "      <td>medic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>option</td>\n",
       "      <td>revenu</td>\n",
       "      <td>period</td>\n",
       "      <td>region</td>\n",
       "      <td>medicar</td>\n",
       "      <td>renew</td>\n",
       "      <td>neg</td>\n",
       "      <td>popul</td>\n",
       "      <td>period</td>\n",
       "      <td>quarter</td>\n",
       "      <td>month</td>\n",
       "      <td>expenditur</td>\n",
       "      <td>period</td>\n",
       "      <td>servic</td>\n",
       "      <td>prospect</td>\n",
       "      <td>payment</td>\n",
       "      <td>notic</td>\n",
       "      <td>methodolog</td>\n",
       "      <td>period</td>\n",
       "      <td>period</td>\n",
       "      <td>spend</td>\n",
       "      <td>nation</td>\n",
       "      <td>conform</td>\n",
       "      <td>physician</td>\n",
       "      <td>hcpc</td>\n",
       "      <td>ifc</td>\n",
       "      <td>part</td>\n",
       "      <td>meet</td>\n",
       "      <td>medicar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>period</td>\n",
       "      <td>reward</td>\n",
       "      <td>potenti</td>\n",
       "      <td>risk</td>\n",
       "      <td>revenu</td>\n",
       "      <td>risk</td>\n",
       "      <td>period</td>\n",
       "      <td>side</td>\n",
       "      <td>region</td>\n",
       "      <td>quarterli</td>\n",
       "      <td>portion</td>\n",
       "      <td>loss</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>snf</td>\n",
       "      <td>servic</td>\n",
       "      <td>secretari</td>\n",
       "      <td>notif</td>\n",
       "      <td>opt</td>\n",
       "      <td>renorm</td>\n",
       "      <td>rebas</td>\n",
       "      <td>type</td>\n",
       "      <td>region</td>\n",
       "      <td>govern</td>\n",
       "      <td>primari</td>\n",
       "      <td>manag</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>prescrib</td>\n",
       "      <td>payment</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>risk</td>\n",
       "      <td>risk</td>\n",
       "      <td>reward</td>\n",
       "      <td>servic</td>\n",
       "      <td>total</td>\n",
       "      <td>termin</td>\n",
       "      <td>poor</td>\n",
       "      <td>track</td>\n",
       "      <td>servic</td>\n",
       "      <td>report</td>\n",
       "      <td>pro</td>\n",
       "      <td>month</td>\n",
       "      <td>report</td>\n",
       "      <td>swing</td>\n",
       "      <td>site</td>\n",
       "      <td>servic</td>\n",
       "      <td>primari</td>\n",
       "      <td>popul</td>\n",
       "      <td>risk</td>\n",
       "      <td>region</td>\n",
       "      <td>uncap</td>\n",
       "      <td>trend</td>\n",
       "      <td>refer</td>\n",
       "      <td>profession</td>\n",
       "      <td>primari</td>\n",
       "      <td>report</td>\n",
       "      <td>prescript</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>pharmaci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule_words</th>\n",
       "      <td>track</td>\n",
       "      <td>track</td>\n",
       "      <td>risk</td>\n",
       "      <td>track</td>\n",
       "      <td>track</td>\n",
       "      <td>track</td>\n",
       "      <td>track</td>\n",
       "      <td>variabl</td>\n",
       "      <td>track</td>\n",
       "      <td>typic</td>\n",
       "      <td>termin</td>\n",
       "      <td>period</td>\n",
       "      <td>sampl</td>\n",
       "      <td>waiver</td>\n",
       "      <td>telehealth</td>\n",
       "      <td>track</td>\n",
       "      <td>templat</td>\n",
       "      <td>primari</td>\n",
       "      <td>score</td>\n",
       "      <td>weight</td>\n",
       "      <td>weight</td>\n",
       "      <td>weight</td>\n",
       "      <td>subpart</td>\n",
       "      <td>specialti</td>\n",
       "      <td>servic</td>\n",
       "      <td>uncontrol</td>\n",
       "      <td>report</td>\n",
       "      <td>track</td>\n",
       "      <td>sponsor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>waivers</td>\n",
       "      <td>receive</td>\n",
       "      <td>beneficiary</td>\n",
       "      <td>retrospective</td>\n",
       "      <td>revenue</td>\n",
       "      <td>complex</td>\n",
       "      <td>telehealth</td>\n",
       "      <td>mlr</td>\n",
       "      <td>funds</td>\n",
       "      <td>0</td>\n",
       "      <td>useful</td>\n",
       "      <td>july</td>\n",
       "      <td>snf</td>\n",
       "      <td>telehealth</td>\n",
       "      <td>patient</td>\n",
       "      <td>stability</td>\n",
       "      <td>opt</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>earlier</td>\n",
       "      <td>historical</td>\n",
       "      <td>achieved</td>\n",
       "      <td>0</td>\n",
       "      <td>voluntary</td>\n",
       "      <td>beginning</td>\n",
       "      <td>0</td>\n",
       "      <td>medication</td>\n",
       "      <td>cehrt</td>\n",
       "      <td>pharmacy</td>\n",
       "      <td>clarification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>participants</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>avoid</td>\n",
       "      <td>prospective</td>\n",
       "      <td>day</td>\n",
       "      <td>oppose</td>\n",
       "      <td>infrastructure</td>\n",
       "      <td>ensure</td>\n",
       "      <td>mechanism</td>\n",
       "      <td>participating</td>\n",
       "      <td>enhancements</td>\n",
       "      <td>30</td>\n",
       "      <td>methodology</td>\n",
       "      <td>association</td>\n",
       "      <td>variable</td>\n",
       "      <td>urges</td>\n",
       "      <td>voluntarily</td>\n",
       "      <td>periods</td>\n",
       "      <td>benchmarking</td>\n",
       "      <td>incentives</td>\n",
       "      <td>18</td>\n",
       "      <td>participating</td>\n",
       "      <td>opt</td>\n",
       "      <td>codes</td>\n",
       "      <td>000</td>\n",
       "      <td>measures</td>\n",
       "      <td>clarify</td>\n",
       "      <td>mips</td>\n",
       "      <td>understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>choose</td>\n",
       "      <td>levels</td>\n",
       "      <td>cms1701p</td>\n",
       "      <td>choose</td>\n",
       "      <td>large</td>\n",
       "      <td>percent</td>\n",
       "      <td>losses</td>\n",
       "      <td>assigned</td>\n",
       "      <td>attractive</td>\n",
       "      <td>participates</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>vs</td>\n",
       "      <td>adjustment</td>\n",
       "      <td>16</td>\n",
       "      <td>ensure</td>\n",
       "      <td>addition</td>\n",
       "      <td>primary</td>\n",
       "      <td>additional</td>\n",
       "      <td>regardless</td>\n",
       "      <td>defining</td>\n",
       "      <td>8</td>\n",
       "      <td>participates</td>\n",
       "      <td>100</td>\n",
       "      <td>added</td>\n",
       "      <td>2012</td>\n",
       "      <td>loss</td>\n",
       "      <td>promoting</td>\n",
       "      <td>aligned</td>\n",
       "      <td>currently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>cause</td>\n",
       "      <td>revenue</td>\n",
       "      <td>election</td>\n",
       "      <td>waivers</td>\n",
       "      <td>21244</td>\n",
       "      <td>dear</td>\n",
       "      <td>community</td>\n",
       "      <td>date</td>\n",
       "      <td>1701</td>\n",
       "      <td>participated</td>\n",
       "      <td>patient</td>\n",
       "      <td>2019</td>\n",
       "      <td>changes</td>\n",
       "      <td>proposal</td>\n",
       "      <td>unnecessary</td>\n",
       "      <td>investments</td>\n",
       "      <td>adjustment</td>\n",
       "      <td>benchmarking</td>\n",
       "      <td>organization</td>\n",
       "      <td>center</td>\n",
       "      <td>importance</td>\n",
       "      <td>participated</td>\n",
       "      <td>retrospective</td>\n",
       "      <td>alliance</td>\n",
       "      <td>2014</td>\n",
       "      <td>comprehensive</td>\n",
       "      <td>2</td>\n",
       "      <td>include</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>mechanism</td>\n",
       "      <td>agreement</td>\n",
       "      <td>patient</td>\n",
       "      <td>annually</td>\n",
       "      <td>low</td>\n",
       "      <td>determining</td>\n",
       "      <td>agree</td>\n",
       "      <td>beneficiary</td>\n",
       "      <td>administrator</td>\n",
       "      <td>participate</td>\n",
       "      <td>possible</td>\n",
       "      <td>date</td>\n",
       "      <td>forward</td>\n",
       "      <td>voluntarily</td>\n",
       "      <td>operations</td>\n",
       "      <td>number</td>\n",
       "      <td>attestation</td>\n",
       "      <td>vs</td>\n",
       "      <td>16</td>\n",
       "      <td>approximately</td>\n",
       "      <td>possible</td>\n",
       "      <td>participate</td>\n",
       "      <td>beneficiary</td>\n",
       "      <td>percent</td>\n",
       "      <td>2019</td>\n",
       "      <td>success</td>\n",
       "      <td>adjustment</td>\n",
       "      <td>sets</td>\n",
       "      <td>based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>participating</td>\n",
       "      <td>1701</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>real</td>\n",
       "      <td>entity</td>\n",
       "      <td>recommend</td>\n",
       "      <td>participations</td>\n",
       "      <td>mssp</td>\n",
       "      <td>participants</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>submit</td>\n",
       "      <td>health</td>\n",
       "      <td>beneficiary</td>\n",
       "      <td>provides</td>\n",
       "      <td>aco</td>\n",
       "      <td>processes</td>\n",
       "      <td>behalf</td>\n",
       "      <td>accurate</td>\n",
       "      <td>physician</td>\n",
       "      <td>participants</td>\n",
       "      <td>following</td>\n",
       "      <td>high</td>\n",
       "      <td>baseline</td>\n",
       "      <td>disease</td>\n",
       "      <td>behalf</td>\n",
       "      <td>comprehensive</td>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>file</td>\n",
       "      <td>shared</td>\n",
       "      <td>focused</td>\n",
       "      <td>aco</td>\n",
       "      <td>behalf</td>\n",
       "      <td>regardless</td>\n",
       "      <td>greater</td>\n",
       "      <td>participation</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>participant</td>\n",
       "      <td>fee</td>\n",
       "      <td>enhanced</td>\n",
       "      <td>3</td>\n",
       "      <td>1701</td>\n",
       "      <td>community</td>\n",
       "      <td>act</td>\n",
       "      <td>services</td>\n",
       "      <td>1701</td>\n",
       "      <td>accurately</td>\n",
       "      <td>www</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>participant</td>\n",
       "      <td>responsible</td>\n",
       "      <td>path</td>\n",
       "      <td>category</td>\n",
       "      <td>access</td>\n",
       "      <td>record</td>\n",
       "      <td>development</td>\n",
       "      <td>participation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>success</td>\n",
       "      <td>recommend</td>\n",
       "      <td>build</td>\n",
       "      <td>choice</td>\n",
       "      <td>result</td>\n",
       "      <td>reduction</td>\n",
       "      <td>participating</td>\n",
       "      <td>participating</td>\n",
       "      <td>sided</td>\n",
       "      <td>partially</td>\n",
       "      <td>address</td>\n",
       "      <td>level</td>\n",
       "      <td>receive</td>\n",
       "      <td>support</td>\n",
       "      <td>medicare</td>\n",
       "      <td>feedback</td>\n",
       "      <td>5</td>\n",
       "      <td>analysis</td>\n",
       "      <td>ms</td>\n",
       "      <td>conditions</td>\n",
       "      <td>3</td>\n",
       "      <td>partially</td>\n",
       "      <td>primary</td>\n",
       "      <td>experience</td>\n",
       "      <td>december</td>\n",
       "      <td>attached</td>\n",
       "      <td>50</td>\n",
       "      <td>encourage</td>\n",
       "      <td>participating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>telehealth</td>\n",
       "      <td>low</td>\n",
       "      <td>date</td>\n",
       "      <td>benchmark</td>\n",
       "      <td>file</td>\n",
       "      <td>participation</td>\n",
       "      <td>expenditures</td>\n",
       "      <td>participates</td>\n",
       "      <td>o</td>\n",
       "      <td>partial</td>\n",
       "      <td>methodology</td>\n",
       "      <td>performance</td>\n",
       "      <td>pleased</td>\n",
       "      <td>risk</td>\n",
       "      <td>16</td>\n",
       "      <td>language</td>\n",
       "      <td>provider</td>\n",
       "      <td>addition</td>\n",
       "      <td>000</td>\n",
       "      <td>better</td>\n",
       "      <td>0</td>\n",
       "      <td>partial</td>\n",
       "      <td>increased</td>\n",
       "      <td>policy</td>\n",
       "      <td>changes</td>\n",
       "      <td>program</td>\n",
       "      <td>proposal</td>\n",
       "      <td>use</td>\n",
       "      <td>participates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_words</th>\n",
       "      <td>accountable</td>\n",
       "      <td>seema</td>\n",
       "      <td>policy</td>\n",
       "      <td>1701</td>\n",
       "      <td>attached</td>\n",
       "      <td>rule</td>\n",
       "      <td>based</td>\n",
       "      <td>participated</td>\n",
       "      <td>rule</td>\n",
       "      <td>parsed</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>assignment</td>\n",
       "      <td>option</td>\n",
       "      <td>health</td>\n",
       "      <td>sincerely</td>\n",
       "      <td>participate</td>\n",
       "      <td>department</td>\n",
       "      <td>medicaid</td>\n",
       "      <td>16</td>\n",
       "      <td>better</td>\n",
       "      <td>parsed</td>\n",
       "      <td>choice</td>\n",
       "      <td>unnecessary</td>\n",
       "      <td>independent</td>\n",
       "      <td>rates</td>\n",
       "      <td>cms</td>\n",
       "      <td>attention</td>\n",
       "      <td>participated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          a2         a3          a4b            a4c       a5b  \\\n",
       "rule_words         agreement       base    agreement         adjust    assign   \n",
       "rule_words              base      basic        basic      agreement      base   \n",
       "rule_words             basic  benchmark        elect         assign     basic   \n",
       "rule_words             defer      level        glide           base        ff   \n",
       "rule_words             level      limit        level      benchmark      high   \n",
       "rule_words             model       loss         path         period       low   \n",
       "rule_words            option     revenu       period         region   medicar   \n",
       "rule_words            period     reward      potenti           risk    revenu   \n",
       "rule_words              risk       risk       reward         servic     total   \n",
       "rule_words             track      track         risk          track     track   \n",
       "comment_words        waivers    receive  beneficiary  retrospective   revenue   \n",
       "comment_words   participants  hospitals        avoid    prospective       day   \n",
       "comment_words         choose     levels     cms1701p         choose     large   \n",
       "comment_words          cause    revenue     election        waivers     21244   \n",
       "comment_words      mechanism  agreement      patient       annually       low   \n",
       "comment_words  participating       1701           26              2      real   \n",
       "comment_words           file     shared      focused            aco    behalf   \n",
       "comment_words        success  recommend        build         choice    result   \n",
       "comment_words     telehealth        low         date      benchmark      file   \n",
       "comment_words    accountable      seema       policy           1701  attached   \n",
       "\n",
       "                         a5c             a5d             a6b            a6c  \\\n",
       "rule_words         agreement         425.316           5,000         adjust   \n",
       "rule_words              base          action          assign      agreement   \n",
       "rule_words             basic       agreement               b         assign   \n",
       "rule_words             enter        corridor             mlr      benchmark   \n",
       "rule_words             model         financi           model           care   \n",
       "rule_words            period         monitor             msr          month   \n",
       "rule_words             renew             neg           popul         period   \n",
       "rule_words              risk          period            side         region   \n",
       "rule_words            termin            poor           track         servic   \n",
       "rule_words             track           track         variabl          track   \n",
       "comment_words        complex      telehealth             mlr          funds   \n",
       "comment_words         oppose  infrastructure          ensure      mechanism   \n",
       "comment_words        percent          losses        assigned     attractive   \n",
       "comment_words           dear       community            date           1701   \n",
       "comment_words    determining           agree     beneficiary  administrator   \n",
       "comment_words         entity       recommend  participations           mssp   \n",
       "comment_words     regardless         greater   participation     healthcare   \n",
       "comment_words      reduction   participating   participating          sided   \n",
       "comment_words  participation    expenditures    participates              o   \n",
       "comment_words           rule           based    participated           rule   \n",
       "\n",
       "                        a6d2          a6d3          a7b          a7c  \\\n",
       "rule_words            applic            30            6            6   \n",
       "rule_words               dai     agreement    agreement    agreement   \n",
       "rule_words             decis          date       assign       assign   \n",
       "rule_words               end        effect    benchmark         juli   \n",
       "rule_words             notic         liabl     calendar         list   \n",
       "rule_words           product          loss     determin        month   \n",
       "rule_words           quarter         month   expenditur       period   \n",
       "rule_words         quarterli       portion         loss      qualiti   \n",
       "rule_words            report           pro        month       report   \n",
       "rule_words             typic        termin       period        sampl   \n",
       "comment_words              0        useful         july          snf   \n",
       "comment_words  participating  enhancements           30  methodology   \n",
       "comment_words   participates  insufficient           vs   adjustment   \n",
       "comment_words   participated       patient         2019      changes   \n",
       "comment_words    participate      possible         date      forward   \n",
       "comment_words   participants             4           10       submit   \n",
       "comment_words    participant           fee     enhanced            3   \n",
       "comment_words      partially       address        level      receive   \n",
       "comment_words        partial   methodology  performance      pleased   \n",
       "comment_words         parsed             3         2020   assignment   \n",
       "\n",
       "                         b2a          b2b           c2          c3a  \\\n",
       "rule_words            assign         1834         1899      425.312   \n",
       "rule_words               bed          act      425.304         care   \n",
       "rule_words               dai      furnish          act         data   \n",
       "rule_words            hospit            l       incent       declin   \n",
       "rule_words     preliminarili       origin         item       inform   \n",
       "rule_words          prospect   practition            m      medicar   \n",
       "rule_words            servic     prospect      payment        notic   \n",
       "rule_words               snf       servic    secretari        notif   \n",
       "rule_words             swing         site       servic      primari   \n",
       "rule_words            waiver   telehealth        track      templat   \n",
       "comment_words     telehealth      patient    stability          opt   \n",
       "comment_words    association     variable        urges  voluntarily   \n",
       "comment_words             16       ensure     addition      primary   \n",
       "comment_words       proposal  unnecessary  investments   adjustment   \n",
       "comment_words    voluntarily   operations       number  attestation   \n",
       "comment_words         health  beneficiary     provides          aco   \n",
       "comment_words           1701    community          act     services   \n",
       "comment_words        support     medicare     feedback            5   \n",
       "comment_words           risk           16     language     provider   \n",
       "comment_words         option       health    sincerely  participate   \n",
       "\n",
       "                        c3b            d2            d3b         d3c  \\\n",
       "rule_words         approach        adjust      agreement      adjust   \n",
       "rule_words           assign     agreement      benchmark      aggreg   \n",
       "rule_words             base        assign     expenditur         cap   \n",
       "rule_words        benchmark     benchmark         histor       enrol   \n",
       "rule_words             care           cap       incorpor     percent   \n",
       "rule_words            claim           hcc     methodolog      region   \n",
       "rule_words       methodolog        period         period       spend   \n",
       "rule_words              opt        renorm          rebas        type   \n",
       "rule_words            popul          risk         region       uncap   \n",
       "rule_words          primari         score         weight      weight   \n",
       "comment_words     benchmark       earlier     historical    achieved   \n",
       "comment_words       periods  benchmarking     incentives          18   \n",
       "comment_words    additional    regardless       defining           8   \n",
       "comment_words  benchmarking  organization         center  importance   \n",
       "comment_words            vs            16  approximately    possible   \n",
       "comment_words     processes        behalf       accurate   physician   \n",
       "comment_words          1701    accurately            www   hospitals   \n",
       "comment_words      analysis            ms     conditions           3   \n",
       "comment_words      addition           000         better           0   \n",
       "comment_words    department      medicaid             16      better   \n",
       "\n",
       "                         d3d             d4           e2           e3  \\\n",
       "rule_words            assign        425.601      425.402        99304   \n",
       "rule_words             blend        425.603          act        99354   \n",
       "rule_words               by3        425.800       assign         care   \n",
       "rule_words            compon            add         care         code   \n",
       "rule_words            counti         adjust    clinician          cpt   \n",
       "rule_words            factor      benchmark       design        evalu   \n",
       "rule_words            nation        conform    physician         hcpc   \n",
       "rule_words            region         govern      primari        manag   \n",
       "rule_words             trend          refer   profession      primari   \n",
       "rule_words            weight        subpart    specialti       servic   \n",
       "comment_words              0      voluntary    beginning            0   \n",
       "comment_words  participating            opt        codes          000   \n",
       "comment_words   participates            100        added         2012   \n",
       "comment_words   participated  retrospective     alliance         2014   \n",
       "comment_words    participate    beneficiary      percent         2019   \n",
       "comment_words   participants      following         high     baseline   \n",
       "comment_words    participant    responsible         path     category   \n",
       "comment_words      partially        primary   experience     december   \n",
       "comment_words        partial      increased       policy      changes   \n",
       "comment_words         parsed         choice  unnecessary  independent   \n",
       "\n",
       "                          e4          e5             e6             e7  \n",
       "rule_words            affect           d         advanc         arrang  \n",
       "rule_words         benchmark        fill            apm           care  \n",
       "rule_words          circumst        http          cehrt        coordin  \n",
       "rule_words          determin      measur      clinician              d  \n",
       "rule_words            disast       misus      criterion           data  \n",
       "rule_words            extrem      opioid           elig          medic  \n",
       "rule_words               ifc        part           meet        medicar  \n",
       "rule_words           qualiti    prescrib        payment           part  \n",
       "rule_words            report   prescript        qualiti       pharmaci  \n",
       "rule_words         uncontrol      report          track        sponsor  \n",
       "comment_words     medication       cehrt       pharmacy  clarification  \n",
       "comment_words       measures     clarify           mips  understanding  \n",
       "comment_words           loss   promoting        aligned      currently  \n",
       "comment_words  comprehensive           2        include        current  \n",
       "comment_words        success  adjustment           sets          based  \n",
       "comment_words        disease      behalf  comprehensive           risk  \n",
       "comment_words         access      record    development  participation  \n",
       "comment_words       attached          50      encourage  participating  \n",
       "comment_words        program    proposal            use   participates  \n",
       "comment_words          rates         cms      attention   participated  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict = {key1:[value1, value2[1]] for (key1, value1), (key2, value2) in zip(termvecs.items(), boost_features.items())}\n",
    "words = pd.DataFrame(data=merged_dict).T.rename({0:\"rule_words\", 1:\"comment_words\"}, axis=1).T\n",
    "words = words.apply(lambda x: x.explode())\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check - synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='headers_expsyn_comsyn_basestop', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last id uploaded: b\n"
     ]
    }
   ],
   "source": [
    "fake_rule_chunks = [{\"section\": \"a\", \"text\": \"AAA and other things and words\"}, \\\n",
    "                    {\"section\": \"b\", \"text\": \"hospitals and other things and words\"}]\n",
    "fake_split = rulesplit_toES(fake_rule_chunks, \"sanity_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_comments = {\"should_match_a\": \"abdominal aortic aneurysm\", \\\n",
    "                 \"should_match_neither\": \"This comment is not relevant to anything\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_match_a should_match_neither "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'should_match_a': {'a': 0.6931471}, 'should_match_neither': {}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_large_query(fake_comments, \"sanity_check\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
